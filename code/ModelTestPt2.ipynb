{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import shap\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, BaseCrossValidator\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error, accuracy_score, median_absolute_error, make_scorer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.plots import plot_convergence\n",
    "from hpsklearn import HyperoptEstimator, any_regressor, any_preprocessing\n",
    "from hyperopt import tpe\n",
    "\n",
    "\n",
    "#Creating a custom time series cross-validator\n",
    "class CustomTimeSeriesCV(BaseCrossValidator):\n",
    "    \"\"\"Creates an iterator that contains the indices from each dataset based on the years given\"\"\"\n",
    "    def __init__(self, years):\n",
    "        self.years = years\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for train_years, test_years in self.years:\n",
    "            train_indices = np.where(X['year'].isin(train_years))[0]\n",
    "            test_indices = np.where(X['year'].isin(test_years))[0]\n",
    "            yield train_indices, test_indices\n",
    "        \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(self.years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_sklearn_model(model, param_dict, X, y, iterations = 50):\n",
    "   \"Creating a custom CV to look through errors in a detailed manner\"\n",
    "   X_other, X_test, y_other, y_test = (X.loc[X['year'] < 2022, :], X.loc[X['year'] == 2022, :], \n",
    "                                    y.loc[X['year'] < 2022], y.loc[X['year'] == 2022])\n",
    "\n",
    "   models = []\n",
    "   test_scores = []\n",
    "   for random_state in range(1, iterations):\n",
    "      \n",
    "      one_hot_fts = ['office_type', 'final_rating', 'open_seat']\n",
    "      std_fts = ['midterm', 'incumbent_margin', 'covi_num','special', 'prev_gb_margin', 'prev2_gb_margin',\n",
    "         'mean_specials_differential', 'pvi', 'previous_cci', 'current_cci',\n",
    "         'previous_gas', 'current_gas',  'previous_unemployment',\n",
    "         'current_unemployment', 'absenteeexcusereq', 'pollhours',\n",
    "         'avgpollhours', 'maxpollhours', 'minpollhours', 'regdeadlines',\n",
    "         'voteridlaws', 'novoterid', 'noallmailvote', 'noearlyvote',\n",
    "         'nofelonreg', 'nofelonsregafterincar', 'nonstrictid', 'nonstrictphoto',\n",
    "         'noonlineregistration', 'nopermanentabsentee', 'nopollplacereg', 'nopr',\n",
    "         'nosamedayreg', 'nostateholiday', 'pr16', 'pr17', 'pr175', 'pr60',\n",
    "         'pr90', 'strictid', 'strictphoto', 'house_chamber_margin',\n",
    "         'senate_chamber_margin', 'change_cci', 'change_unemployment']\n",
    "         \n",
    "      preprocessor = ColumnTransformer([\n",
    "      ('cat', OneHotEncoder(), one_hot_fts), \n",
    "      ('num', 'passthrough', std_fts)])\n",
    "      \n",
    "      parameters = {key: value.rvs(random_state=random_state) for key, value in param_dict.items()}\n",
    "      model = model.set_params(**parameters)\n",
    "      \n",
    "      pipe = make_pipeline(preprocessor, model)\n",
    "      models.append(pipe)\n",
    "      \n",
    "      folds = [(range(2002, 2006, 2), [2006, 2008]),\n",
    "         (range(2006, 2010, 2), [2010, 2012]),\n",
    "         (range(2010, 2014, 2), [2014, 2016]),\n",
    "         (range(2014, 2018, 2), [2018, 2020])]\n",
    "      \n",
    "      fold_scores = []\n",
    "      for train, test in folds:\n",
    "            X_train, X_val = X_other.loc[X['year'].isin(train), :], X_other.loc[X['year'].isin(test), :]\n",
    "            y_train, y_val = y_other[X_other['year'].isin(train)], y_other[X_other['year'].isin(test)]\n",
    "            \n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_pred = pipe.predict(X_val)\n",
    "            fold_scores.append(median_absolute_error(y_val, y_pred))\n",
    "            #print(f'Mean absolute error for {train} is {mean_absolute_error(y_val, y_pred)}')\n",
    "            #print(f'Mean squared error for {train} is {mean_squared_error(y_val, y_pred)}')\n",
    "            #print(f'Max error for {train} is {max_error(y_val, y_pred)}')\n",
    "            #print(f'Median absolute error for {train} is {median_absolute_error(y_val, y_pred)}')\n",
    "            #print('---------------------------------------------------------')\n",
    "      test_scores.append(np.mean(fold_scores))\n",
    "   \n",
    "   \n",
    "   best_model = models[np.argmin(test_scores)]\n",
    "   best_model.fit(X_other, y_other)\n",
    "   train_score = mean_absolute_error(y_other, best_model.predict(X_other))\n",
    "   val_score = test_scores[np.argmin(test_scores)]\n",
    "   test_score = mean_absolute_error(y_test, best_model.predict(X_test))\n",
    "\n",
    "   print(\"Results for Manual Cross-Validation:\")\n",
    "   print(f\"training score is {train_score}\")\n",
    "   print(f\"validation score is {val_score}\")\n",
    "   print(f\"test_score is {test_score}\")\n",
    "   return best_model, train_score, val_score, test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_model(model, param_dict, X, y, iterations = 75):\n",
    "    \"\"\"Runs through a given model to get the best estimator of that model, as well as the train/test score values.\"\"\"\n",
    "    X_other, X_test, y_other, y_test = (X.loc[X['year'] < 2022, :], X.loc[X['year'] == 2022, :], \n",
    "                                        y.loc[X['year'] < 2022], y.loc[X['year'] == 2022])\n",
    "    \n",
    "    folds = [(range(2002, 2006, 2), [2006, 2008]),\n",
    "        (range(2006, 2010, 2), [2010, 2012]),\n",
    "        (range(2010, 2014, 2), [2014, 2016]),\n",
    "        (range(2014, 2018, 2), [2018, 2020])]\n",
    "\n",
    "    cv = CustomTimeSeriesCV(folds)\n",
    "        \n",
    "    one_hot_fts = ['office_type', 'final_rating', 'open_seat']\n",
    "    std_fts = ['midterm', 'incumbent_margin', 'covi_num','special', 'prev_gb_margin', 'prev2_gb_margin',\n",
    "       'mean_specials_differential', 'pvi', 'previous_cci', 'current_cci',\n",
    "       'previous_gas', 'current_gas',  'previous_unemployment',\n",
    "       'current_unemployment', 'absenteeexcusereq', 'pollhours',\n",
    "       'avgpollhours', 'maxpollhours', 'minpollhours', 'regdeadlines',\n",
    "       'voteridlaws', 'novoterid', 'noallmailvote', 'noearlyvote',\n",
    "       'nofelonreg', 'nofelonsregafterincar', 'nonstrictid', 'nonstrictphoto',\n",
    "       'noonlineregistration', 'nopermanentabsentee', 'nopollplacereg', 'nopr',\n",
    "       'nosamedayreg', 'nostateholiday', 'pr16', 'pr17', 'pr175', 'pr60',\n",
    "       'pr90', 'strictid', 'strictphoto', 'house_chamber_margin',\n",
    "       'senate_chamber_margin', 'change_cci', 'change_unemployment']\n",
    "        \n",
    "    preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(), one_hot_fts), \n",
    "    ('num', 'passthrough', std_fts)])\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "        \n",
    "    param_dict = {f\"{model_name.lower()}__{key}\": value for key, value in param_dict.items()}\n",
    "    \n",
    "    pipe = make_pipeline(preprocessor, model)\n",
    "    \n",
    "    grid = RandomizedSearchCV(pipe, param_dict, n_iter=iterations, scoring='neg_median_absolute_error', cv = cv, verbose = 1)\n",
    "    grid.fit(X_other, y_other)\n",
    "    train_score_mae = mean_absolute_error(y_other, grid.predict(X_other))\n",
    "    val_score_mae = grid.best_score_\n",
    "    test_score_mae = mean_absolute_error(y_test, grid.predict(X_test))\n",
    "    \n",
    "    print(\"Results for Sklearn Cross-Validation:\")\n",
    "    print(f\"training score is {train_score_mae}\")\n",
    "    print(f\"validation score is {val_score_mae}\")\n",
    "    print(f\"test_score is {test_score_mae}\")\n",
    "    \n",
    "    return (grid, train_score_mae, val_score_mae, test_score_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../cleaned_data/Finalized Dataset.csv\")\n",
    "filtered_data = data.drop(columns = ['district']).assign(pvi = lambda x: x['pvi'] * 2, \n",
    "                                                         midterm = lambda x: x['year'] % 4 != 0)\n",
    "X = filtered_data.drop(columns=['margin'])\n",
    "y = filtered_data['margin']\n",
    "\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': randint(10, 251),  # Discrete uniform distribution\n",
    "    'max_depth': randint(3, 16),  # Discrete uniform distribution\n",
    "    'learning_rate': uniform(0.001, 0.199),  # Continuous uniform distribution\n",
    "    'subsample': uniform(0.3, 0.7),  # Continuous uniform distribution\n",
    "    'colsample_bytree': uniform(0.3, 0.7),  # Continuous uniform distribution\n",
    "    'min_child_weight': randint(5, 16),  # Discrete uniform distribution\n",
    "    'gamma': uniform(0.01, 99.99),  # Continuous uniform distribution\n",
    "    'reg_alpha': uniform(0.01, 99.99),  # Continuous uniform distribution\n",
    "    'reg_lambda': uniform(0.01, 99.99)  # Continuous uniform distribution\n",
    "}\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_jobs = -1)\n",
    "#no_sklearn_model(xgb, param_dist_xgb, X, y, iterations = 50)\n",
    "(grid, _, _, _) = sklearn_model(xgb, param_dist_xgb, X, y, iterations = 50)\n",
    "print(grid.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt = xgboost.XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
    "             colsample_bylevel=None, colsample_bynode=None,\n",
    "             colsample_bytree=0.8037356348820666, early_stopping_rounds=None,\n",
    "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "             gamma=7.392364374366169, gpu_id=None, grow_policy=None,\n",
    "             importance_type=None, interaction_constraints=None,\n",
    "             learning_rate=0.04199619532047469, max_bin=None,\n",
    "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
    "             min_child_weight=7, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=68, n_jobs=-1, num_parallel_tree=None, predictor=None,\n",
    "             random_state=None, ...)\n",
    "\n",
    "sklearn = xgboost.XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
    "             colsample_bylevel=None, colsample_bynode=None,\n",
    "             colsample_bytree=0.7724255609402491, early_stopping_rounds=None,\n",
    "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "             gamma=14.095496265247299, gpu_id=None, grow_policy=None,\n",
    "             importance_type=None, interaction_constraints=None,\n",
    "             learning_rate=0.152283064794593, max_bin=None,\n",
    "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
    "             min_child_weight=10, monotone_constraints=None,\n",
    "             n_estimators=107, n_jobs=-1, num_parallel_tree=None,\n",
    "             predictor=None, random_state=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
