{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import lightgbm as lgb\n",
    "import xgboost\n",
    "import re\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from sklearn.metrics import  accuracy_score, median_absolute_error, make_scorer\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "class CustomTimeSeriesCV(BaseCrossValidator):\n",
    "    \"\"\"Creates an iterator that contains the indices from each dataset based on the years given\"\"\"\n",
    "    def __init__(self, years):\n",
    "        self.years = years\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for train_years, test_years in self.years:\n",
    "            train_indices = np.where(X['year'].isin(train_years))[0]\n",
    "            test_indices = np.where(X['year'].isin(test_years))[0]\n",
    "            yield train_indices, test_indices\n",
    "        \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(self.years) \n",
    "    \n",
    "def penalize_wrong(y, y_pred, penalty):\n",
    "    \"Penalizes wrong guesses more, determined by the value of k\"\n",
    "    return np.mean(abs((y_pred - y))*(1+penalty*(np.sign(y_pred)\n",
    "                                               != np.sign(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "#Categorical features that need to be one-hot encoded    \n",
    "one_hot_fts = ['office_type']\n",
    "\n",
    "#Rating is the only ordinal feature\n",
    "ordinal_fts = ['final_rating']\n",
    "ordinal_fts_ranking = ['Safe R', 'Likely R', 'Leans R', 'Toss-up', 'Leans D', 'Likely D', 'Safe D']\n",
    "\n",
    "#Cont features that should be pass-throughed (and later scaled)\n",
    "cont_fts = ['open_seat','incumbent_differential', 'absenteeexcusereq', 'special', 'isMidterm',\n",
    "       'pollhours', 'avgpollhours', 'minpollhours', 'regdeadlines',\n",
    "       'voteridlaws', 'novoterid', 'noallmailvote', 'noearlyvote',\n",
    "       'nofelonreg', 'nofelonsregafterincar', 'nonstrictid', 'nonstrictphoto',\n",
    "       'nopollplacereg', 'nopr', 'nosamedayreg', 'nostateholiday', 'pr16',\n",
    "       'pr17', 'pr175', 'pr60', 'pr90', 'strictid', 'strictphoto', 'covi_num',\n",
    "       'prev_gen_margin', 'prev_dem_gen_tp', 'weighted_genpoll', 'unweighted_genpoll',\n",
    "       'mean_specials_differential', 'house_chamber_margin',\n",
    "       'senate_chamber_margin', 'previous_cci', 'current_cci', 'change_cci',\n",
    "       'previous_gas', 'current_gas', 'change_gas', 'previous_unemployment',\n",
    "       'current_unemployment', 'change_unemployment', 'receipts_DEM',\n",
    "       'receipts_REP', 'disbursements_DEM', 'disbursements_REP',\n",
    "       'unconvinced_pct', 'phone_unweighted', 'online_unweighted', 'num_polls',\n",
    "       'unweighted_estimate', 'unweighted_ci_lower', 'unweighted_ci_upper',\n",
    "       'weighted_estimate', 'weighted_ci_lower', 'weighted_ci_upper',\n",
    "       'white_pct', 'black_pct', 'asian_pct', 'hispanic_pct', 'median_income',\n",
    "       'impoverished_pct', 'median_age', 'renting_pct', 'inflation',\n",
    "       'isMidterm', 'receipts_ratio', 'disbursements_ratio', 'total_receipts',\n",
    "       'total_disbursements', 'genballot_predicted_margin',\n",
    "       'specials_predicted_margin', 'receipts_genballot_interaction', 'poll_fundamental_agree',\n",
    "       'disbursements_genballot_interaction', 'gas_democrat_interaction', 'cci_democrat_interaction']\n",
    "\n",
    "def optima_model(model, param_dict, X, y, penalizing_factor = 10):\n",
    "    \"\"\"Performs hyperparameter optimization for a a given bootstrapped X \n",
    "    ## Parameters:\n",
    "    model: sklearnable model. We use LGBMRegressor \n",
    "    param_dict: dictionary of hyperparameters to optimize\n",
    "    X: DataFrame with features\n",
    "    y: Series with target variable\"\"\"\n",
    "    \n",
    "    X_other, y_other = X.loc[X['year'] <= 2022, :], y.loc[X['year'] <= 2022]\n",
    "    X_train, X_test, y_train, y_test = (X.loc[X['year'] < 2022, :], X.loc[X['year'] == 2022, :], \n",
    "                                        y.loc[X['year'] < 2022], y.loc[X['year'] == 2022])\n",
    "    \n",
    "    # Create fold structure so we can make a custom cross-validation for time-series\n",
    "    folds = [\n",
    "        (range(2002, 2006, 2), [2006, 2008]),\n",
    "        (range(2002, 2010, 2), [2010, 2012]),\n",
    "        (range(2002, 2014, 2), [2014, 2016]),\n",
    "        (range(2002, 2018, 2), [2020])\n",
    "    ]\n",
    "\n",
    "    cv = CustomTimeSeriesCV(folds)\n",
    "        \n",
    "    #Preprocessing data: no need to scale data, because we use tree-based models which are monotonic-scale-invariant\n",
    "    #Because we don't need to scale data, we don't have to include the column transformer in the final saved model\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "    \n",
    "    def objective(params):\n",
    "        print(\"Params: \", params)\n",
    "        \"Function that takes in hyperparameters and returns loss, that Hyperopt will minimize.\"        \n",
    "        testing_loss = []\n",
    "        accuracies = []\n",
    "        for train_idx, test_idx in cv.split(X_train):\n",
    "            reg = model(**params)\n",
    "            pipe = Pipeline(steps = [\n",
    "                ('preprocessing', preprocessor), \n",
    "                ('model', reg)])\n",
    "            \n",
    "            \n",
    "            #Necessary steps to utilize early-stopping on LGBM\n",
    "            pipe.named_steps['preprocessing'].fit(X_train.iloc[train_idx])\n",
    "            transformed_val = pipe.named_steps['preprocessing'].transform(X_train.iloc[test_idx])\n",
    "            penalize_scorer = make_scorer(penalize_wrong, greaterisbetter=False, penalizing_factor = penalizing_factor)\n",
    "\n",
    "            \n",
    "            \"\"\"Goes through each fold and calculates loss.\n",
    "            Note: We use median absolute error because it is more robust to outliers than mean absolute error.\n",
    "            We also expect earlier folds to have higher error, since they have less data to train on.\"\"\"\n",
    "            early_stopping = lgb.early_stopping(10, verbose = False)\n",
    "            \n",
    "            pipe.fit(X_train.iloc[train_idx], y_train.iloc[train_idx],\n",
    "                     model__eval_set = [(transformed_val, y_train.iloc[test_idx])], model__eval_metric = 'mae', \n",
    "                     model__callbacks = [early_stopping])            \n",
    "            \n",
    "            \n",
    "            predictions = pipe.predict(X_train.iloc[test_idx])\n",
    "            testing_loss.append(penalize_wrong(y_train.iloc[test_idx], predictions, penalizing_factor))\n",
    "            accuracies.append(accuracy_score(np.sign(y_train.iloc[test_idx]), np.sign(predictions)))\n",
    "            \n",
    "        mean_test_loss = np.mean(testing_loss)\n",
    "        print(f\"Validation loss: {testing_loss}, mean: {mean_test_loss}\")\n",
    "        print(f\"Validation accuracy: {accuracies}, mean: {np.mean(accuracies)}\")\n",
    "        return {'loss': mean_test_loss, 'status': STATUS_OK}\n",
    "\n",
    "    start_time = time.time()\n",
    "    max_time = 240 #about two minutes per run-through\n",
    "    def stop(trial, elapsed_time=0):\n",
    "        return elapsed_time > max_time, [time.time() - start_time] \n",
    "    \n",
    "    \"Hyperopt uses the TPE algorithm to optimize hyperparameters. We use the no_progress_loss function to stop early if we don't see progress.\"\n",
    "    best_params = fmin(fn=objective,\n",
    "                    space=param_dict,\n",
    "                    algo=tpe.suggest,\n",
    "                    trials=Trials(),\n",
    "                    early_stop_fn = stop)\n",
    "                    \n",
    "                    \n",
    "    print(\"Best parameters:\", best_params)\n",
    "    best_model = model(**best_params)\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('preprocessing', preprocessor), \n",
    "        ('model', best_model)])\n",
    "    \n",
    "    #Returns a fitted ML algortithm with those hyperparameters\n",
    "    pipe.fit(X_other, y_other) \n",
    "    #Returns the final model   \n",
    "    return pipe.named_steps['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params:                                                                \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6224482338512769, 'learning_rate': 0.008852201067224334, 'max_depth': 12, 'min_child_samples': 120, 'min_data_in_bin': 2, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 34, 'reg_alpha': 1.3342346523867976, 'reg_lambda': 1.5794853052646247, 'subsample': 0.6843912978586495, 'subsample_for_bin': 178988, 'verbose': -1}\n",
      "Validation loss: [20.79555055363765, 18.84052079244883, 17.95867593871686, 15.697943616255476], mean: 18.323172725264705\n",
      "Validation accuracy: [0.9299781181619255, 0.9372384937238494, 0.9442467378410438, 0.9428571428571428], mean: 0.9385801231459905\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.4293922242783459, 'learning_rate': 0.038192383635948554, 'max_depth': 12, 'min_child_samples': 62, 'min_data_in_bin': 2, 'min_data_in_leaf': 9, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 68, 'reg_alpha': 2.0543296517885707, 'reg_lambda': 1.53783467660771, 'subsample': 0.7491975252484212, 'subsample_for_bin': 181677, 'verbose': -1}\n",
      "Validation loss: [18.40290467971672, 11.905903307179074, 11.873640174389937, 12.269335871736436], mean: 13.612946008255543\n",
      "Validation accuracy: [0.925601750547046, 0.944560669456067, 0.9466192170818505, 0.936734693877551], mean: 0.9383790827406285\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.41305476154836807, 'learning_rate': 0.04883341019260814, 'max_depth': 6, 'min_child_samples': 97, 'min_data_in_bin': 4, 'min_data_in_leaf': 6, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 40, 'reg_alpha': 0.5656028362464363, 'reg_lambda': 1.189827213523666, 'subsample': 0.5782311673498469, 'subsample_for_bin': 78702, 'verbose': -1}\n",
      "Validation loss: [17.15534692094267, 11.969299270332181, 11.751360454225622, 11.486013316006753], mean: 13.090504990376806\n",
      "Validation accuracy: [0.9266958424507659, 0.9456066945606695, 0.9466192170818505, 0.9469387755102041], mean: 0.9414651324008725\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.4975904715166515, 'learning_rate': 0.013482567199896558, 'max_depth': 8, 'min_child_samples': 20, 'min_data_in_bin': 9, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 48, 'reg_alpha': 0.24458891092846657, 'reg_lambda': 2.235788662640488, 'subsample': 0.6186826826666485, 'subsample_for_bin': 90993, 'verbose': -1}\n",
      "Validation loss: [17.91497562117346, 14.872130856757982, 14.52265656539125, 13.303575100593376], mean: 15.153334535979019\n",
      "Validation accuracy: [0.936542669584245, 0.9456066945606695, 0.9466192170818505, 0.9408163265306122], mean: 0.9423962269393443\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7121396069714435, 'learning_rate': 0.027054628828013, 'max_depth': 5, 'min_child_samples': 76, 'min_data_in_bin': 2, 'min_data_in_leaf': 2, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 63, 'reg_alpha': 2.481904067148216, 'reg_lambda': 1.6984765092711758, 'subsample': 0.5650482797027262, 'subsample_for_bin': 35406, 'verbose': -1}\n",
      "Validation loss: [18.160095046565193, 12.825495161798814, 11.835135298116866, 11.56458141336853], mean: 13.596326729962351\n",
      "Validation accuracy: [0.9266958424507659, 0.9456066945606695, 0.9489916963226572, 0.9448979591836735], mean: 0.9415480481294415\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5484825420979773, 'learning_rate': 0.17734094516001567, 'max_depth': 6, 'min_child_samples': 49, 'min_data_in_bin': 6, 'min_data_in_leaf': 7, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 57, 'reg_alpha': 0.3863310258750899, 'reg_lambda': 1.51534314602733, 'subsample': 0.6299856113832776, 'subsample_for_bin': 169480, 'verbose': -1}\n",
      "Validation loss: [17.891833536511445, 13.311464877286621, 11.818041127007564, 11.537072852968922], mean: 13.639603098443636\n",
      "Validation accuracy: [0.9266958424507659, 0.9476987447698745, 0.9478054567022538, 0.9469387755102041], mean: 0.9422847048582745\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5957610125620662, 'learning_rate': 0.01776051733340101, 'max_depth': 4, 'min_child_samples': 102, 'min_data_in_bin': 3, 'min_data_in_leaf': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 57, 'reg_alpha': 2.161318196676153, 'reg_lambda': 0.06314820684577088, 'subsample': 0.7177133029863916, 'subsample_for_bin': 95109, 'verbose': -1}\n",
      "Validation loss: [17.369517180092785, 13.944364160237832, 11.847811295030136, 11.797901967234944], mean: 13.739898650648923\n",
      "Validation accuracy: [0.9288840262582057, 0.9424686192468619, 0.9537366548042705, 0.9448979591836735], mean: 0.9424968148732529\n",
      "Params:                                                                                                           \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6971941923036582, 'learning_rate': 0.039856010925427635, 'max_depth': 10, 'min_child_samples': 62, 'min_data_in_bin': 9, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 24, 'reg_alpha': 2.2786592690203533, 'reg_lambda': 1.7122068955738934, 'subsample': 0.7444784339876704, 'subsample_for_bin': 143716, 'verbose': -1}\n",
      "Validation loss: [16.57784429805603, 12.055273577167485, 11.472789849388318, 11.517669068176922], mean: 12.905894198197188\n",
      "Validation accuracy: [0.9299781181619255, 0.9476987447698745, 0.9525504151838672, 0.9448979591836735], mean: 0.9437813093248352\n",
      "Params:                                                                                                           \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.4990259179780081, 'learning_rate': 0.004063491630927215, 'max_depth': 6, 'min_child_samples': 111, 'min_data_in_bin': 2, 'min_data_in_leaf': 9, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 61, 'reg_alpha': 1.7328726950064757, 'reg_lambda': 0.7283015980955077, 'subsample': 0.7327843944285033, 'subsample_for_bin': 186021, 'verbose': -1}\n",
      "Validation loss: [25.19573764631018, 26.58100103413507, 26.21919788476332, 23.770761311153418], mean: 25.441674469090497\n",
      "Validation accuracy: [0.9343544857768052, 0.9173640167364017, 0.9193357058125742, 0.9163265306122449], mean: 0.9218451847345065\n",
      "Params:                                                                                                           \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5531214236399131, 'learning_rate': 0.038529109056582175, 'max_depth': 13, 'min_child_samples': 39, 'min_data_in_bin': 3, 'min_data_in_leaf': 9, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 38, 'reg_alpha': 1.7315636262911214, 'reg_lambda': 0.9048763996156606, 'subsample': 0.6489995241132894, 'subsample_for_bin': 116593, 'verbose': -1}\n",
      "Validation loss: [17.42810859944678, 11.67959787946935, 11.764752699033101, 11.641336029139175], mean: 13.128448801772102\n",
      "Validation accuracy: [0.9288840262582057, 0.9497907949790795, 0.9489916963226572, 0.9448979591836735], mean: 0.9431411191859039\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.40054408219935006, 'learning_rate': 0.008793525443723407, 'max_depth': 8, 'min_child_samples': 49, 'min_data_in_bin': 7, 'min_data_in_leaf': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 39, 'reg_alpha': 0.8906304116712151, 'reg_lambda': 0.45776638450801904, 'subsample': 0.7418351846257742, 'subsample_for_bin': 53826, 'verbose': -1}\n",
      "Validation loss: [19.80913600392638, 18.348567385423248, 17.413445017020614, 16.406168622593807], mean: 17.994329257241013\n",
      "Validation accuracy: [0.9321663019693655, 0.9403765690376569, 0.9478054567022538, 0.9408163265306122], mean: 0.940291163559972\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.497927559707802, 'learning_rate': 0.04899928972993628, 'max_depth': 9, 'min_child_samples': 109, 'min_data_in_bin': 3, 'min_data_in_leaf': 5, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 53, 'reg_alpha': 1.7568917806581819, 'reg_lambda': 2.2901446538127015, 'subsample': 0.5232907568371833, 'subsample_for_bin': 36008, 'verbose': -1}\n",
      "Validation loss: [16.73011890383653, 11.707919014155411, 11.462873341051992, 11.396982856409691], mean: 12.824473528863408\n",
      "Validation accuracy: [0.9277899343544858, 0.9456066945606695, 0.9478054567022538, 0.9448979591836735], mean: 0.9415250112002705\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6832345135908755, 'learning_rate': 0.010626287306691297, 'max_depth': 11, 'min_child_samples': 137, 'min_data_in_bin': 5, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 69, 'reg_alpha': 2.1973063549559897, 'reg_lambda': 0.14969006231819237, 'subsample': 0.7048479039593943, 'subsample_for_bin': 61289, 'verbose': -1}\n",
      "Validation loss: [19.329677963121238, 17.362332622289607, 16.52234628809819, 14.699871755338137], mean: 16.978557157211792\n",
      "Validation accuracy: [0.9310722100656456, 0.9341004184100419, 0.9442467378410438, 0.9387755102040817], mean: 0.9370487191302033\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5276140461354747, 'learning_rate': 0.006411430927696442, 'max_depth': 9, 'min_child_samples': 143, 'min_data_in_bin': 7, 'min_data_in_leaf': 7, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 64, 'reg_alpha': 0.5614660969165258, 'reg_lambda': 2.413254106616265, 'subsample': 0.7635080484312559, 'subsample_for_bin': 51067, 'verbose': -1}\n",
      "Validation loss: [22.549529008812787, 22.076052546413816, 21.17089989364501, 20.569900027311512], mean: 21.591595369045784\n",
      "Validation accuracy: [0.9288840262582057, 0.9309623430962343, 0.9347568208778173, 0.9204081632653062], mean: 0.9287528383743909\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7716762718744208, 'learning_rate': 0.016679993661954547, 'max_depth': 6, 'min_child_samples': 40, 'min_data_in_bin': 9, 'min_data_in_leaf': 4, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 42, 'reg_alpha': 1.5783181252327163, 'reg_lambda': 1.9028587568773823, 'subsample': 0.7377910090490815, 'subsample_for_bin': 96850, 'verbose': -1}\n",
      "Validation loss: [17.905981952302003, 14.262041866393144, 13.51134943151546, 12.289564818531987], mean: 14.492234517185649\n",
      "Validation accuracy: [0.9299781181619255, 0.9403765690376569, 0.9478054567022538, 0.9387755102040817], mean: 0.9392339135264794\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.43603193645775007, 'learning_rate': 0.04811719895890227, 'max_depth': 3, 'min_child_samples': 33, 'min_data_in_bin': 3, 'min_data_in_leaf': 5, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 62, 'reg_alpha': 0.4484129802432446, 'reg_lambda': 1.0938726780960464, 'subsample': 0.7715409855017727, 'subsample_for_bin': 29523, 'verbose': -1}\n",
      "Validation loss: [21.66260308627242, 13.885779990998417, 12.107971939357014, 12.11333722536751], mean: 14.94242306049884\n",
      "Validation accuracy: [0.9091903719912473, 0.9424686192468619, 0.9501779359430605, 0.9428571428571428], mean: 0.9361735175095782\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5777345013400625, 'learning_rate': 0.3153720948989185, 'max_depth': 13, 'min_child_samples': 97, 'min_data_in_bin': 9, 'min_data_in_leaf': 1, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 67, 'reg_alpha': 1.8197118127684933, 'reg_lambda': 2.0781066425426813, 'subsample': 0.7320707112399789, 'subsample_for_bin': 149994, 'verbose': -1}\n",
      "Validation loss: [17.263127059946253, 12.035197819324903, 12.346697005814024, 13.233459490281547], mean: 13.719620343841681\n",
      "Validation accuracy: [0.9277899343544858, 0.9497907949790795, 0.9454329774614472, 0.9346938775510204], mean: 0.9394268960865082\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6439756578443228, 'learning_rate': 0.09839617023017948, 'max_depth': 11, 'min_child_samples': 23, 'min_data_in_bin': 6, 'min_data_in_leaf': 4, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 39, 'reg_alpha': 1.962459551562081, 'reg_lambda': 1.7492309017334828, 'subsample': 0.657543462496864, 'subsample_for_bin': 117610, 'verbose': -1}\n",
      "Validation loss: [15.697183106254547, 12.341783341594871, 12.02735461346396, 11.735897706926965], mean: 12.950554692060084\n",
      "Validation accuracy: [0.9387308533916849, 0.9476987447698745, 0.9466192170818505, 0.9448979591836735], mean: 0.9444866936067708\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.44049680748521625, 'learning_rate': 0.15975687413667963, 'max_depth': 13, 'min_child_samples': 137, 'min_data_in_bin': 9, 'min_data_in_leaf': 7, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 64, 'reg_alpha': 0.5226969406305843, 'reg_lambda': 2.4945627288316947, 'subsample': 0.7525107980420905, 'subsample_for_bin': 21399, 'verbose': -1}\n",
      "Validation loss: [16.666060706846697, 13.453992865572229, 11.59349240494578, 12.252886841170477], mean: 13.491608204633796\n",
      "Validation accuracy: [0.9343544857768052, 0.9435146443514645, 0.9454329774614472, 0.9346938775510204], mean: 0.9394989962851843\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.48077719442881056, 'learning_rate': 0.004669745591379682, 'max_depth': 14, 'min_child_samples': 47, 'min_data_in_bin': 6, 'min_data_in_leaf': 3, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 47, 'reg_alpha': 0.8539161350098043, 'reg_lambda': 1.829771343031196, 'subsample': 0.7078064569432038, 'subsample_for_bin': 167396, 'verbose': -1}\n",
      "Validation loss: [24.24250255997528, 24.73827409369769, 24.132629821666562, 22.83631326957138], mean: 23.987429936227727\n",
      "Validation accuracy: [0.9321663019693655, 0.9246861924686193, 0.9276393831553974, 0.9183673469387755], mean: 0.9257148061330394\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7997383394399316, 'learning_rate': 0.08615754444950828, 'max_depth': 10, 'min_child_samples': 63, 'min_data_in_bin': 8, 'min_data_in_leaf': 5, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 24, 'reg_alpha': 2.4832545920177886, 'reg_lambda': 2.1869030436723533, 'subsample': 0.5107235656570641, 'subsample_for_bin': 190331, 'verbose': -1}\n",
      "Validation loss: [16.76448029617131, 12.16936241772111, 12.025499230710851, 11.431458162385665], mean: 13.097700026747235\n",
      "Validation accuracy: [0.9321663019693655, 0.9456066945606695, 0.9501779359430605, 0.9448979591836735], mean: 0.9432122229141923\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7409729972311755, 'learning_rate': 0.07981458588721392, 'max_depth': 7, 'min_child_samples': 103, 'min_data_in_bin': 1, 'min_data_in_leaf': 5, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 53, 'reg_alpha': 1.4253889321163355, 'reg_lambda': 1.328229175230271, 'subsample': 0.7996479836851677, 'subsample_for_bin': 38993, 'verbose': -1}\n",
      "Validation loss: [18.45493875105544, 11.914243214692354, 11.716928685802708, 11.542183829895652], mean: 13.407073620361537\n",
      "Validation accuracy: [0.9223194748358862, 0.948744769874477, 0.9501779359430605, 0.9448979591836735], mean: 0.9415350349592743\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6592338419035154, 'learning_rate': 0.022647297937814056, 'max_depth': 10, 'min_child_samples': 28, 'min_data_in_bin': 1, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 29, 'reg_alpha': 2.3875311542460778, 'reg_lambda': 2.3908833319586638, 'subsample': 0.506561020856788, 'subsample_for_bin': 38506, 'verbose': -1}\n",
      "Validation loss: [18.427957344725513, 13.349735225395005, 12.230734379611091, 11.664679950551964], mean: 13.918276725070893\n",
      "Validation accuracy: [0.925601750547046, 0.9424686192468619, 0.9478054567022538, 0.9448979591836735], mean: 0.9401934464199587\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7023017903917783, 'learning_rate': 0.35495402873843623, 'max_depth': 2, 'min_child_samples': 109, 'min_data_in_bin': 8, 'min_data_in_leaf': 5, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 21, 'reg_alpha': 1.1406819147535237, 'reg_lambda': 2.116323265055331, 'subsample': 0.7998503353470978, 'subsample_for_bin': 89500, 'verbose': -1}\n",
      "Validation loss: [21.14549768570431, 18.47150642687796, 16.471690249450614, 16.279333173885107], mean: 18.092006883979497\n",
      "Validation accuracy: [0.9102844638949672, 0.9288702928870293, 0.9288256227758007, 0.9183673469387755], mean: 0.9215869316241432\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7518735161019305, 'learning_rate': 0.06401308476982745, 'max_depth': 9, 'min_child_samples': 108, 'min_data_in_bin': 3, 'min_data_in_leaf': 6, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 44, 'reg_alpha': 2.2646462092527715, 'reg_lambda': 2.0303225103301714, 'subsample': 0.5481705852907434, 'subsample_for_bin': 199046, 'verbose': -1}\n",
      "Validation loss: [16.580860040653803, 11.82655538151194, 11.804213504023755, 11.679397388229239], mean: 12.972756578604685\n",
      "Validation accuracy: [0.9354485776805251, 0.9497907949790795, 0.9501779359430605, 0.9428571428571428], mean: 0.944568612864952\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.46652393717270335, 'learning_rate': 0.14038516762747513, 'max_depth': 10, 'min_child_samples': 133, 'min_data_in_bin': 4, 'min_data_in_leaf': 2, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 22, 'reg_alpha': 1.910992133169278, 'reg_lambda': 1.3778473962938271, 'subsample': 0.5958209333112119, 'subsample_for_bin': 96832, 'verbose': -1}\n",
      "Validation loss: [16.07425967454851, 11.912744058335523, 11.175192623684023, 12.771714823777097], mean: 12.983477795086289\n",
      "Validation accuracy: [0.9321663019693655, 0.9497907949790795, 0.9489916963226572, 0.9408163265306122], mean: 0.9429412799504286\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6236229277254758, 'learning_rate': 0.21511036542694328, 'max_depth': 9, 'min_child_samples': 69, 'min_data_in_bin': 5, 'min_data_in_leaf': 1, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 60, 'reg_alpha': 1.1435331133080084, 'reg_lambda': 1.9393827813467837, 'subsample': 0.522321122869104, 'subsample_for_bin': 110141, 'verbose': -1}\n",
      "Validation loss: [17.603662514228787, 11.661329908375963, 12.123198300476544, 12.564657663203423], mean: 13.488212096571178\n",
      "Validation accuracy: [0.9332603938730853, 0.9476987447698745, 0.9501779359430605, 0.9408163265306122], mean: 0.9429883502791582\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5244598796994694, 'learning_rate': 0.028794461629168273, 'max_depth': 4, 'min_child_samples': 34, 'min_data_in_bin': 9, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 36, 'reg_alpha': 1.564578170466907, 'reg_lambda': 2.316318930328952, 'subsample': 0.6735446239942808, 'subsample_for_bin': 83671, 'verbose': -1}\n",
      "Validation loss: [17.595672802817628, 12.758250719650707, 11.57032533348129, 11.59324987737175], mean: 13.379374683330344\n",
      "Validation accuracy: [0.9310722100656456, 0.9456066945606695, 0.9513641755634639, 0.9448979591836735], mean: 0.9432352598433631\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6161182574979522, 'learning_rate': 0.11345713013446544, 'max_depth': 2, 'min_child_samples': 114, 'min_data_in_bin': 3, 'min_data_in_leaf': 5, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 28, 'reg_alpha': 1.3428763176563767, 'reg_lambda': 1.6322892420671142, 'subsample': 0.7842276807463907, 'subsample_for_bin': 56477, 'verbose': -1}\n",
      "Validation loss: [24.57413757429748, 15.298830688249355, 13.090887799325762, 13.327709870637126], mean: 16.57289148312743\n",
      "Validation accuracy: [0.9004376367614879, 0.9372384937238494, 0.9501779359430605, 0.936734693877551], mean: 0.9311471900764872\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.6732528521777251, 'learning_rate': 0.0653958829271508, 'max_depth': 10, 'min_child_samples': 84, 'min_data_in_bin': 3, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 33, 'reg_alpha': 2.3387382594799018, 'reg_lambda': 1.445505988085677, 'subsample': 0.6886544588927065, 'subsample_for_bin': 109330, 'verbose': -1}\n",
      "Validation loss: [17.347122228719467, 11.85727621313694, 11.725385192305414, 11.490383703040191], mean: 13.105041834300504\n",
      "Validation accuracy: [0.9288840262582057, 0.948744769874477, 0.9489916963226572, 0.9448979591836735], mean: 0.9428796129097533\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.791472674419631, 'learning_rate': 0.04145300648043263, 'max_depth': 12, 'min_child_samples': 62, 'min_data_in_bin': 8, 'min_data_in_leaf': 2, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 59, 'reg_alpha': 2.110730048338135, 'reg_lambda': 0.8659889953239659, 'subsample': 0.5303738244453042, 'subsample_for_bin': 64232, 'verbose': -1}\n",
      "Validation loss: [16.43406943077738, 11.759891293088353, 12.144773827877236, 11.76319124200754], mean: 13.025481448437628\n",
      "Validation accuracy: [0.9343544857768052, 0.948744769874477, 0.9489916963226572, 0.9387755102040817], mean: 0.9427166155445054\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.7229627965692899, 'learning_rate': 0.22920234044751026, 'max_depth': 3, 'min_child_samples': 44, 'min_data_in_bin': 4, 'min_data_in_leaf': 6, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 32, 'reg_alpha': 1.575005188592466, 'reg_lambda': 1.1532980910329642, 'subsample': 0.5991555794826114, 'subsample_for_bin': 150605, 'verbose': -1}\n",
      "Validation loss: [22.07803773406455, 14.23313021205596, 12.228920493287783, 13.493362359437324], mean: 15.508362699711405\n",
      "Validation accuracy: [0.9059080962800875, 0.9382845188284519, 0.9513641755634639, 0.9387755102040817], mean: 0.9335830752190212\n",
      "Params:                                                                                                             \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5743214945308597, 'learning_rate': 0.060257143001883375, 'max_depth': 9, 'min_child_samples': 21, 'min_data_in_bin': 9, 'min_data_in_leaf': 8, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 25, 'reg_alpha': 1.9998484566030292, 'reg_lambda': 1.5723736001786266, 'subsample': 0.62938134800931, 'subsample_for_bin': 140252, 'verbose': -1}\n",
      "Validation loss: [16.190803434251148, 11.708074451169741, 11.371074814125146, 11.442699288182967], mean: 12.67816299693225\n",
      "Validation accuracy: [0.9343544857768052, 0.950836820083682, 0.9525504151838672, 0.9428571428571428], mean: 0.9451497159753743\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5720159014695637, 'learning_rate': 0.061295278198299365, 'max_depth': 9, 'min_child_samples': 93, 'min_data_in_bin': 7, 'min_data_in_leaf': 1, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 51, 'reg_alpha': 1.9507900712358526, 'reg_lambda': 1.0043983612131346, 'subsample': 0.5532138829046509, 'subsample_for_bin': 131469, 'verbose': -1}\n",
      "Validation loss: [16.498036999769706, 11.81037795153119, 11.37251985967082, 11.321834333023613], mean: 12.750692285998834\n",
      "Validation accuracy: [0.936542669584245, 0.946652719665272, 0.9525504151838672, 0.9448979591836735], mean: 0.9451609409042644\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5833808539450662, 'learning_rate': 0.11938865119294084, 'max_depth': 9, 'min_child_samples': 21, 'min_data_in_bin': 7, 'min_data_in_leaf': 1, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 25, 'reg_alpha': 2.010494779218446, 'reg_lambda': 0.5707233397777046, 'subsample': 0.56280266986983, 'subsample_for_bin': 66135, 'verbose': -1}\n",
      "Validation loss: [17.173858713686343, 12.30539486986507, 11.313562949005922, 11.51916476789932], mean: 13.077995325114163\n",
      "Validation accuracy: [0.9321663019693655, 0.9476987447698745, 0.9537366548042705, 0.9448979591836735], mean: 0.9446249151817959\n",
      "Params:                                                                                                            \n",
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.5657015677229602, 'learning_rate': 0.022299052344274973, 'max_depth': 5, 'min_child_samples': 36, 'min_data_in_bin': 7, 'min_data_in_leaf': 1, 'monotone_constraints': (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0), 'num_leaves': 51, 'reg_alpha': 0.9665536696016259, 'reg_lambda': 0.3397304661838506, 'subsample': 0.6128911140613872, 'subsample_for_bin': 45231, 'verbose': -1}\n",
      "  0%|          | 35/9223372036854775807 [02:06<9235928913410680:36:16,  3.60s/trial, best loss: 12.67816299693225]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 45\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Define the search space for Hyperopt\u001b[39;00m\n\u001b[1;32m     27\u001b[0m param_dist_lgbm \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboosting_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Removed 'goss' to simplify\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m70\u001b[39m),  \u001b[38;5;66;03m# Reduced the upper limit, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonotone_constraints\u001b[39m\u001b[38;5;124m'\u001b[39m: monotone_constraints\n\u001b[1;32m     42\u001b[0m }\n\u001b[0;32m---> 45\u001b[0m \u001b[43moptima_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBMRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_dist_lgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m num_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_trials):\n",
      "Cell \u001b[0;32mIn[66], line 106\u001b[0m, in \u001b[0;36moptima_model\u001b[0;34m(model, param_dict, X, y, penalizing_factor)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m max_time, [time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time] \n\u001b[1;32m    105\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperopt uses the TPE algorithm to optimize hyperparameters. We use the no_progress_loss function to stop early if we don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt see progress.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 106\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n\u001b[1;32m    114\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[66], line 86\u001b[0m, in \u001b[0;36moptima_model.<locals>.objective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Goes through each fold and calculates loss.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03mNote: We use median absolute error because it is more robust to outliers than mean absolute error.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03mWe also expect earlier folds to have higher error, since they have less data to train on.\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mearly_stopping(\u001b[38;5;241m10\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 86\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmodel__eval_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel__eval_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmodel__callbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m     91\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_train\u001b[38;5;241m.\u001b[39miloc[test_idx])\n\u001b[1;32m     92\u001b[0m testing_loss\u001b[38;5;241m.\u001b[39mappend(penalize_wrong(y_train\u001b[38;5;241m.\u001b[39miloc[test_idx], predictions, penalizing_factor))\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/sklearn.py:1092\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1077\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Bootstraps X and y, and then runs the optimization function\n",
    "def bootstrap(group, n=None):\n",
    "    if n is None:\n",
    "        n = len(group)\n",
    "    return group.sample(n, replace=True)\n",
    "\n",
    "data = pd.read_csv(\"../cleaned_data/Engineered Dataset.csv\")\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "\n",
    "names_for_monotonicity = preprocessor.fit(data.drop(columns=['margin'])).get_feature_names_out()\n",
    "before_processing_monotonic_columns = ['incumbent_differential', 'pvi', 'receipts_ratio', 'disbursements_ratio', \n",
    "                                       'genballot_predicted_margin', 'specials_predicted_margin', 'unweighted_estimate', 'unweighted_ci_lower',\n",
    "                                       'unweighted_ci_upper','weighted_estimate', 'weighted_ci_lower', 'weighted_ci_upper',\n",
    "                                       'phone_unweighted', 'online_unweighted', 'receipts_genballot_interaction',\n",
    "                                       'disbursements_genballot_interaction', 'poll_fundamental_average']\n",
    "\n",
    "monotonic_columns = ['num__' + name for name in before_processing_monotonic_columns]\n",
    "monotone_constraints = [1 if name in monotonic_columns else 0 for name in names_for_monotonicity]\n",
    "\n",
    "# Define the search space for Hyperopt\n",
    "param_dist_lgbm = {\n",
    "    'boosting_type': 'gbdt',  # Removed 'goss' to simplify\n",
    "    'num_leaves': hp.randint('num_leaves', 20, 70),  # Reduced the upper limit, \n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, -1),  # Equivalent to about 0.0001 to 0.01\n",
    "    'subsample_for_bin': hp.randint('subsample_for_bin', 20000, 200000),  # Narrowed the range\n",
    "    'min_data_in_bin': hp.randint('min_data_in_bin', 1, 10), \n",
    "    'min_data_in_leaf': hp.randint('min_data_in_leaf', 1, 10),  # Reduced the upper limit\n",
    "    'min_child_samples': hp.randint('min_child_samples', 20, 150),  # Increased the range for more regularization\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.5),  # Increased upper limit for L1 regularization\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 2.5),  # Increased upper limit for L2 regularization\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8),  # Reduced the upper limit\n",
    "    'subsample': hp.uniform('subsample', 0.5, 0.8),  # Reduced the upper limit for more randomness\n",
    "    'max_depth': hp.randint('max_depth', 2, 15),  # Added max_depth for additional control\n",
    "    \"verbose\": -1,  # Keep verbose to -1 to reduce log clutter, \n",
    "    'monotone_constraints': monotone_constraints\n",
    "}\n",
    "\n",
    "\n",
    "optima_model(lgb.LGBMRegressor, param_dist_lgbm, data.drop(columns=['margin']), data['margin'])\n",
    "\n",
    "num_trials = 0\n",
    "for idx in range(num_trials):\n",
    "    bootstrapped_data = data.groupby(['year', 'office_type']).apply(bootstrap).reset_index(drop=True)\n",
    "    \n",
    "    bootstrapped_X = bootstrapped_data.drop(columns=['margin'])\n",
    "    bootstrapped_y = bootstrapped_data['margin']\n",
    "    \n",
    "    trained_lgbm = optima_model(lgb.LGBMRegressor, param_dist_lgbm, bootstrapped_X, bootstrapped_y)\n",
    "    file_path = f\"../models/Model_{idx}.pkl\"\n",
    "\n",
    "    # Open a file to write in binary mode\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pkl.dump(trained_lgbm, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
