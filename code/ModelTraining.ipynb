{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import lightgbm as lgb\n",
    "import xgboost\n",
    "import re\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from sklearn.metrics import  accuracy_score, median_absolute_error, make_scorer\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "class CustomTimeSeriesCV(BaseCrossValidator):\n",
    "    \"\"\"Creates an iterator that contains the indices from each dataset based on the years given\"\"\"\n",
    "    def __init__(self, years):\n",
    "        self.years = years\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for train_years, test_years in self.years:\n",
    "            train_indices = np.where(X['year'].isin(train_years))[0]\n",
    "            test_indices = np.where(X['year'].isin(test_years))[0]\n",
    "            yield train_indices, test_indices\n",
    "        \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(self.years) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "#Categorical features that need to be one-hot encoded    \n",
    "one_hot_fts = ['state', 'office_type']\n",
    "\n",
    "#Rating is the only ordinal feature\n",
    "ordinal_fts = ['final_rating']\n",
    "ordinal_fts_ranking = ['Safe R', 'Likely R', 'Leans R', 'Toss-up', 'Leans D', 'Likely D', 'Safe D']\n",
    "\n",
    "#Cont features that should be pass-throughed (and later scaled)\n",
    "cont_fts = [\n",
    "    \"open_seat\", \"incumbent_differential\", \"special\", \"absenteeexcusereq\", \"pollhours\", \"avgpollhours\", \"minpollhours\",\n",
    "    \"regdeadlines\", \"voteridlaws\", \"novoterid\", \"noallmailvote\", \"noearlyvote\", \"nofelonreg\",\n",
    "    \"nofelonsregafterincar\", \"nonstrictid\", \"nonstrictphoto\", \"nopollplacereg\", \"nopr\", \"nosamedayreg\",\n",
    "    \"nostateholiday\", \"pr16\", \"pr17\", \"pr175\", \"pr60\", \"pr90\", \"strictid\", \"strictphoto\", \"covi_num\",\n",
    "    \"prev_dem_gen_tp\", \"prev_gen_margin\", \"weighted_genpoll\", \"weighted_genpoll_lower\",\n",
    "    \"weighted_genpoll_upper\", \"unweighted_genpoll\", \"mean_specials_differential\", \n",
    "    \"house_chamber_margin\", \"senate_chamber_margin\", \"previous_cci\", \"current_cci\", \"change_cci\",\n",
    "    \"previous_gas\", \"current_gas\", \"change_gas\", \"previous_unemployment\", \"current_unemployment\",\n",
    "    \"change_unemployment\",  \"receipts\", \"from_committee_transfers\", \"disbursements\",\n",
    "    \"to_committee_transfers\", \"beginning_cash\", \"ending_cash\", \"candidate_contributions\",\n",
    "    \"individual_contributions\", \"unconvinced_pct\", \"phone_unweighted\", \"online_unweighted\", \"num_polls\",\n",
    "    \"unweighted_estimate\", \"unweighted_ci_lower\", \"unweighted_ci_upper\", \"weighted_estimate\",\n",
    "    \"weighted_ci_lower\", \"weighted_ci_upper\", \"white_pct\", \"black_pct\", \"asian_pct\", \"hispanic_pct\",\n",
    "    \"median_income\", \"impoverished_pct\", \"median_age\", \"renting_pct\", \"inflation\", \"isMidterm\",\n",
    "    \"genballot_predicted_margin\", \"genballot_predicted_lower\", \"genballot_predicted_upper\",\n",
    "    \"poll_fundamental_agree\",  'receipts_DEM', 'receipts_REP', 'disbursements_DEM', 'disbursements_REP'\n",
    "]\n",
    "\n",
    "def optima_model(model, param_dict, X, y, penalizing_factor = 4):\n",
    "    \"\"\"Performs hyperparameter optimization for a a given bootstrapped X \n",
    "    ## Parameters:\n",
    "    model: sklearnable model. We use LGBMRegressor \n",
    "    param_dict: dictionary of hyperparameters to optimize\n",
    "    X: DataFrame with features\n",
    "    y: Series with target variable\"\"\"\n",
    "    \n",
    "    def penalize_wrong(y, y_pred, penalty):\n",
    "        return np.mean(abs(y_pred - y) * (1 + penalty * (np.sign(y_pred) != np.sign(y))))\n",
    "    \n",
    "    X_other, y_other = X.loc[X['year'] <= 2022, :], y.loc[X['year'] <= 2022]\n",
    "    X_train, X_test, y_train, y_test = (X.loc[X['year'] < 2022, :], X.loc[X['year'] == 2022, :], \n",
    "                                        y.loc[X['year'] < 2022], y.loc[X['year'] == 2022])\n",
    "    \n",
    "    \n",
    "    # Create fold structure so we can make a custom cross-validation for time-series\n",
    "    folds = [\n",
    "        (range(2002, 2010, 2), [2010, 2012]),\n",
    "        (range(2002, 2014, 2), [2014, 2016]),\n",
    "        (range(2002, 2018, 2), [2018, 2020])\n",
    "    ]\n",
    "\n",
    "    cv = CustomTimeSeriesCV(folds)\n",
    "        \n",
    "    #Preprocessing data: no need to scale data, because we use tree-based models which are monotonic-scale-invariant\n",
    "    #Because we don't need to scale data, we don't have to include the column transformer in the final saved model\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "    \n",
    "    def objective(params):\n",
    "        \"Function that takes in hyperparameters and returns loss, that Hyperopt will minimize.\"        \n",
    "        training_loss = []\n",
    "        testing_loss = []\n",
    "        accuracies = []\n",
    "        for train_idx, test_idx in cv.split(X_train):\n",
    "            \n",
    "            reg = model(**params)\n",
    "            pipe = Pipeline(steps = [\n",
    "                ('preprocessing', preprocessor), \n",
    "                ('model', reg)])\n",
    "            \n",
    "            \"\"\"Goes through each fold and calculates loss.\n",
    "            Note: We use median absolute error because it is more robust to outliers than mean absolute error.\n",
    "            We also expect earlier folds to have higher error, since they have less data to train on.\"\"\"\n",
    "            pipe.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
    "            \n",
    "            predictions = pipe.predict(X_train.iloc[test_idx])\n",
    "            training_preds = pipe.predict(X_train.iloc[train_idx])\n",
    "            testing_loss.append(penalize_wrong(y_train.iloc[test_idx], predictions, penalizing_factor))\n",
    "            training_loss.append(penalize_wrong(y_train.iloc[train_idx], training_preds, penalizing_factor))\n",
    "            accuracies.append(accuracy_score(np.sign(y_train.iloc[test_idx]), np.sign(predictions)))\n",
    "         \n",
    "        return {'loss': np.mean(testing_loss), 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    max_time = 120 #about two minutes per run-through\n",
    "    def stop(trial, elapsed_time=0):\n",
    "        return elapsed_time > max_time, [time.time() - start_time] \n",
    "    \n",
    "    \"Hyperopt uses the TPE algorithm to optimize hyperparameters. We use the no_progress_loss function to stop early if we don't see progress.\"\n",
    "    best_params = fmin(fn=objective,\n",
    "                    space=param_dict,\n",
    "                    algo=tpe.suggest,\n",
    "                    trials=Trials(),\n",
    "                    early_stop_fn = stop)\n",
    "                    \n",
    "                    \n",
    "    print(\"Best parameters:\", best_params)\n",
    "    best_model = model(**best_params)\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('preprocessing', preprocessor), \n",
    "        ('model', best_model)])\n",
    "    \n",
    "    #Returns a fitted ML algortithm with those hyperparameters\n",
    "    pipe.fit(X_other, y_other) \n",
    "    #Returns the final model   \n",
    "    return pipe.named_steps['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/9223372036854775807 [00:50<14268253935650313:06:08,  5.57s/trial, best loss: 9.292528501630335] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m bootstrapped_X \u001b[38;5;241m=\u001b[39m bootstrapped_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m bootstrapped_y \u001b[38;5;241m=\u001b[39m bootstrapped_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 53\u001b[0m trained_lgbm \u001b[38;5;241m=\u001b[39m \u001b[43moptima_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBMRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_dist_lgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbootstrapped_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbootstrapped_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/Model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Open a file to write in binary mode????        \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 95\u001b[0m, in \u001b[0;36moptima_model\u001b[0;34m(model, param_dict, X, y, penalizing_factor)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m max_time, [time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time] \n\u001b[1;32m     94\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperopt uses the TPE algorithm to optimize hyperparameters. We use the no_progress_loss function to stop early if we don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt see progress.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 95\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n\u001b[1;32m    103\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[8], line 78\u001b[0m, in \u001b[0;36moptima_model.<locals>.objective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     71\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     72\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessing\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor), \n\u001b[1;32m     73\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, reg)])\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Goes through each fold and calculates loss.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03mNote: We use median absolute error because it is more robust to outliers than mean absolute error.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mWe also expect earlier folds to have higher error, since they have less data to train on.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_train\u001b[38;5;241m.\u001b[39miloc[test_idx])\n\u001b[1;32m     81\u001b[0m training_preds \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_train\u001b[38;5;241m.\u001b[39miloc[train_idx])\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/sklearn.py:1092\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1077\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Bootstraps X and y, and then runs the optimization function\n",
    "def bootstrap(group, n=None):\n",
    "    if n is None:\n",
    "        n = len(group)\n",
    "    return group.sample(n, replace=True)\n",
    "\n",
    "data = pd.read_csv(\"../cleaned_data/Engineered Dataset.csv\")\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "\n",
    "names_for_monotonicity = preprocessor.fit(data.drop(columns=['margin'])).get_feature_names_out()\n",
    "before_processing_monotonic_columns = ['incumbent_differential', 'pvi', 'receipts_ratio', 'disbursements_ratio', \n",
    "                                       'genballot_predicted_margin', 'specials_predicted_margin', 'unweighted_estimate', 'unweighted_ci_lower',\n",
    "                                       'unweighted_ci_upper','weighted_estimate', 'weighted_ci_lower', 'weighted_ci_upper',\n",
    "                                       'phone_unweighted', 'online_unweighted', 'receipts_genballot_interaction',\n",
    "                                       'disbursements_genballot_interaction', 'poll_fundamental_average']\n",
    "\n",
    "monotonic_columns = ['num__' + name for name in before_processing_monotonic_columns] + ['ord__final_rating']\n",
    "monotone_constraints = [1 if name in monotonic_columns else 0 for name in names_for_monotonicity]\n",
    "\n",
    "# Define the search space for Hyperopt\n",
    "param_dist_lgbm = {\n",
    "    'boosting_type': 'dart',\n",
    "    'num_leaves': hp.randint('num_leaves', 20, 70),  # Reduced the upper limit, \n",
    "    'n_estimators': hp.randint('n_estimators', 50, 200),  # Increased the range\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -2),  # Equivalent to about 0.0001 to 0.01\n",
    "    'subsample_for_bin': hp.randint('subsample_for_bin', 20000, 200000),  # Narrowed the range\n",
    "    'min_data_in_bin': hp.randint('min_data_in_bin', 1, 10), \n",
    "    'min_data_in_leaf': hp.randint('min_data_in_leaf', 1, 10),  # Reduced the upper limit\n",
    "    'min_child_samples': hp.randint('min_child_samples', 20, 150),  # Increased the range for more regularization\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.5),  # Increased upper limit for L1 regularization\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.5),  # Increased upper limit for L2 regularization\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8),  # Reduced the upper limit\n",
    "    'subsample': hp.uniform('subsample', 0.5, 0.8),  # Reduced the upper limit for more randomness\n",
    "    'max_depth': hp.randint('max_depth', 2, 10),  # Added max_depth for additional control\n",
    "    \"verbose\": -1,  # Keep verbose to -1 to reduce log clutter, \n",
    "    'monotone_constraints': monotone_constraints\n",
    "}\n",
    "\n",
    "\n",
    "num_trials = 1000\n",
    "for idx in range(num_trials):\n",
    "    bootstrapped_data = data.groupby(['year', 'office_type']).apply(bootstrap).reset_index(drop=True)\n",
    "    \n",
    "    bootstrapped_X = bootstrapped_data.drop(columns=['margin'])\n",
    "    bootstrapped_y = bootstrapped_data['margin']\n",
    "    \n",
    "    trained_lgbm = optima_model(lgb.LGBMRegressor, param_dist_lgbm, bootstrapped_X, bootstrapped_y)\n",
    "    file_path = f\"../models/Model_{idx}.pkl\"\n",
    "\n",
    "    # Open a file to write in binary mode????        \n",
    "    with open(file_path, 'wb') as file:\n",
    "        pkl.dump(trained_lgbm, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed0</th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>office_type</th>\n",
       "      <th>open_seat</th>\n",
       "      <th>incumbent_differential</th>\n",
       "      <th>margin</th>\n",
       "      <th>special</th>\n",
       "      <th>absenteeexcusereq</th>\n",
       "      <th>...</th>\n",
       "      <th>genballot_predicted_margin</th>\n",
       "      <th>genballot_predicted_lower</th>\n",
       "      <th>genballot_predicted_upper</th>\n",
       "      <th>specials_predicted_margin</th>\n",
       "      <th>receipts_genballot_interaction</th>\n",
       "      <th>disbursements_genballot_interaction</th>\n",
       "      <th>democrat_in_presidency</th>\n",
       "      <th>gas_democrat_interaction</th>\n",
       "      <th>cci_democrat_interaction</th>\n",
       "      <th>poll_fundamental_agree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>3746</td>\n",
       "      <td>2022</td>\n",
       "      <td>AK</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.313342</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.872868</td>\n",
       "      <td>-19.171587</td>\n",
       "      <td>-16.573529</td>\n",
       "      <td>-12.826667</td>\n",
       "      <td>-9.125252</td>\n",
       "      <td>-6.884324</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>3747</td>\n",
       "      <td>2022</td>\n",
       "      <td>AL</td>\n",
       "      <td>2</td>\n",
       "      <td>House</td>\n",
       "      <td>False</td>\n",
       "      <td>1.081648</td>\n",
       "      <td>-39.930439</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.391220</td>\n",
       "      <td>-36.689939</td>\n",
       "      <td>-34.091882</td>\n",
       "      <td>-30.345019</td>\n",
       "      <td>82.593152</td>\n",
       "      <td>66.754214</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>3748</td>\n",
       "      <td>2022</td>\n",
       "      <td>AL</td>\n",
       "      <td>3</td>\n",
       "      <td>House</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.500547</td>\n",
       "      <td>-46.082056</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.053414</td>\n",
       "      <td>-44.352134</td>\n",
       "      <td>-41.754076</td>\n",
       "      <td>-38.007213</td>\n",
       "      <td>233.573105</td>\n",
       "      <td>210.000879</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>3749</td>\n",
       "      <td>2022</td>\n",
       "      <td>AL</td>\n",
       "      <td>4</td>\n",
       "      <td>House</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.897236</td>\n",
       "      <td>-70.484282</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.210103</td>\n",
       "      <td>-72.508823</td>\n",
       "      <td>-69.910765</td>\n",
       "      <td>-66.163902</td>\n",
       "      <td>300.501716</td>\n",
       "      <td>268.725624</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>3750</td>\n",
       "      <td>2022</td>\n",
       "      <td>AL</td>\n",
       "      <td>5</td>\n",
       "      <td>House</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-37.535854</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.172868</td>\n",
       "      <td>-36.471587</td>\n",
       "      <td>-33.873529</td>\n",
       "      <td>-30.126667</td>\n",
       "      <td>153.421936</td>\n",
       "      <td>159.031281</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>5267</td>\n",
       "      <td>2022</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "      <td>Governor</td>\n",
       "      <td>False</td>\n",
       "      <td>5.148912</td>\n",
       "      <td>-32.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.241511</td>\n",
       "      <td>-26.540231</td>\n",
       "      <td>-23.942173</td>\n",
       "      <td>-20.195310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>5268</td>\n",
       "      <td>2022</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>Governor</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.701332</td>\n",
       "      <td>-10.900000</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.133995</td>\n",
       "      <td>-15.432714</td>\n",
       "      <td>-12.834656</td>\n",
       "      <td>-9.087794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>5269</td>\n",
       "      <td>2022</td>\n",
       "      <td>VT</td>\n",
       "      <td>0</td>\n",
       "      <td>Governor</td>\n",
       "      <td>False</td>\n",
       "      <td>-72.513675</td>\n",
       "      <td>-47.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.301650</td>\n",
       "      <td>-44.600370</td>\n",
       "      <td>-42.002312</td>\n",
       "      <td>-38.255450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>5270</td>\n",
       "      <td>2022</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>Governor</td>\n",
       "      <td>False</td>\n",
       "      <td>0.455868</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.096188</td>\n",
       "      <td>-6.394908</td>\n",
       "      <td>-3.796850</td>\n",
       "      <td>-0.049988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>5271</td>\n",
       "      <td>2022</td>\n",
       "      <td>WY</td>\n",
       "      <td>0</td>\n",
       "      <td>Governor</td>\n",
       "      <td>False</td>\n",
       "      <td>10.079360</td>\n",
       "      <td>-61.900000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.323920</td>\n",
       "      <td>-43.622640</td>\n",
       "      <td>-41.024582</td>\n",
       "      <td>-37.277719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3.769</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed0  year state  district office_type open_seat  \\\n",
       "3745      3746  2022    AK         1       House      True   \n",
       "3746      3747  2022    AL         2       House     False   \n",
       "3747      3748  2022    AL         3       House     False   \n",
       "3748      3749  2022    AL         4       House     False   \n",
       "3749      3750  2022    AL         5       House      True   \n",
       "...        ...   ...   ...       ...         ...       ...   \n",
       "5266      5267  2022    TN         0    Governor     False   \n",
       "5267      5268  2022    TX         0    Governor     False   \n",
       "5268      5269  2022    VT         0    Governor     False   \n",
       "5269      5270  2022    WI         0    Governor     False   \n",
       "5270      5271  2022    WY         0    Governor     False   \n",
       "\n",
       "      incumbent_differential     margin  special  absenteeexcusereq  ...  \\\n",
       "3745                0.000000  -0.313342    False                0.0  ...   \n",
       "3746                1.081648 -39.930439    False                1.0  ...   \n",
       "3747               -2.500547 -46.082056    False                1.0  ...   \n",
       "3748               -2.897236 -70.484282    False                1.0  ...   \n",
       "3749                0.000000 -37.535854    False                1.0  ...   \n",
       "...                      ...        ...      ...                ...  ...   \n",
       "5266                5.148912 -32.000000    False                1.0  ...   \n",
       "5267               -1.701332 -10.900000    False                1.0  ...   \n",
       "5268              -72.513675 -47.200000    False                0.0  ...   \n",
       "5269                0.455868   3.400000    False                0.0  ...   \n",
       "5270               10.079360 -61.900000    False                0.0  ...   \n",
       "\n",
       "      genballot_predicted_margin  genballot_predicted_lower  \\\n",
       "3745                  -17.872868                 -19.171587   \n",
       "3746                  -35.391220                 -36.689939   \n",
       "3747                  -43.053414                 -44.352134   \n",
       "3748                  -71.210103                 -72.508823   \n",
       "3749                  -35.172868                 -36.471587   \n",
       "...                          ...                        ...   \n",
       "5266                  -25.241511                 -26.540231   \n",
       "5267                  -14.133995                 -15.432714   \n",
       "5268                  -43.301650                 -44.600370   \n",
       "5269                   -5.096188                  -6.394908   \n",
       "5270                  -42.323920                 -43.622640   \n",
       "\n",
       "      genballot_predicted_upper  specials_predicted_margin  \\\n",
       "3745                 -16.573529                 -12.826667   \n",
       "3746                 -34.091882                 -30.345019   \n",
       "3747                 -41.754076                 -38.007213   \n",
       "3748                 -69.910765                 -66.163902   \n",
       "3749                 -33.873529                 -30.126667   \n",
       "...                         ...                        ...   \n",
       "5266                 -23.942173                 -20.195310   \n",
       "5267                 -12.834656                  -9.087794   \n",
       "5268                 -42.002312                 -38.255450   \n",
       "5269                  -3.796850                  -0.049988   \n",
       "5270                 -41.024582                 -37.277719   \n",
       "\n",
       "      receipts_genballot_interaction  disbursements_genballot_interaction  \\\n",
       "3745                       -9.125252                            -6.884324   \n",
       "3746                       82.593152                            66.754214   \n",
       "3747                      233.573105                           210.000879   \n",
       "3748                      300.501716                           268.725624   \n",
       "3749                      153.421936                           159.031281   \n",
       "...                              ...                                  ...   \n",
       "5266                             NaN                                  NaN   \n",
       "5267                             NaN                                  NaN   \n",
       "5268                             NaN                                  NaN   \n",
       "5269                             NaN                                  NaN   \n",
       "5270                             NaN                                  NaN   \n",
       "\n",
       "      democrat_in_presidency  gas_democrat_interaction  \\\n",
       "3745                    True                     3.769   \n",
       "3746                    True                     3.769   \n",
       "3747                    True                     3.769   \n",
       "3748                    True                     3.769   \n",
       "3749                    True                     3.769   \n",
       "...                      ...                       ...   \n",
       "5266                    True                     3.769   \n",
       "5267                    True                     3.769   \n",
       "5268                    True                     3.769   \n",
       "5269                    True                     3.769   \n",
       "5270                    True                     3.769   \n",
       "\n",
       "      cci_democrat_interaction  poll_fundamental_agree  \n",
       "3745                      58.6                    -1.0  \n",
       "3746                      58.6                     NaN  \n",
       "3747                      58.6                     NaN  \n",
       "3748                      58.6                     NaN  \n",
       "3749                      58.6                     NaN  \n",
       "...                        ...                     ...  \n",
       "5266                      58.6                     1.0  \n",
       "5267                      58.6                     1.0  \n",
       "5268                      58.6                     1.0  \n",
       "5269                      58.6                     1.0  \n",
       "5270                      58.6                     1.0  \n",
       "\n",
       "[467 rows x 109 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data['year'] == 2022)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
