{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import shap\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from sklearn.metrics import  make_scorer, mean_pinball_loss\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "\n",
    "class CustomTimeSeriesCV(BaseCrossValidator):\n",
    "    \"\"\"Creates an iterator that contains the indices from each dataset based on the years given\"\"\"\n",
    "    def __init__(self, years):\n",
    "        self.years = years\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for train_years, test_years in self.years:\n",
    "            train_indices = np.where(X['year'].isin(train_years))[0]\n",
    "            test_indices = np.where(X['year'].isin(test_years))[0]\n",
    "            yield train_indices, test_indices\n",
    "        \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(self.years) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "#Categorical features that need to be one-hot encoded    \n",
    "one_hot_fts = ['office_type']\n",
    "\n",
    "#Rating is the only ordinal feature\n",
    "ordinal_fts = ['final_rating']\n",
    "ordinal_fts_ranking = ['Safe R', 'Likely R', 'Leans R', 'Toss-up', 'Leans D', 'Likely D', 'Safe D']\n",
    "\n",
    "#Cont features that should be pass-throughed (aznd later scaled)\n",
    "cont_fts = [\n",
    "    \"open_seat\", \"incumbent_differential\", \"special\", \"absenteeexcusereq\", \"pollhours\", \"avgpollhours\", \"minpollhours\",\n",
    "    \"regdeadlines\", \"voteridlaws\", \"novoterid\", \"noallmailvote\", \"noearlyvote\", \"nofelonreg\",\n",
    "    \"nofelonsregafterincar\", \"nonstrictid\", \"nonstrictphoto\", \"nopollplacereg\", \"nopr\", \"nosamedayreg\",\n",
    "    \"nostateholiday\", \"pr16\", \"pr17\", \"pr175\", \"pr60\", \"pr90\", \"strictid\", \"strictphoto\", \"covi_num\",\n",
    "    \"prev_dem_gen_tp\", \"prev_gen_margin\", \"weighted_genpoll\", \"weighted_genpoll_lower\",\n",
    "    \"weighted_genpoll_upper\", \"unweighted_genpoll\", \"mean_specials_differential\", \n",
    "    \"house_chamber_margin\", \"senate_chamber_margin\", \"previous_cci\", \"current_cci\", \"change_cci\",\n",
    "    \"previous_gas\", \"current_gas\", \"change_gas\", \"previous_unemployment\", \"current_unemployment\",\n",
    "    \"change_unemployment\",  \"receipts\", \"from_committee_transfers\", \"disbursements\",\n",
    "    \"to_committee_transfers\", \"beginning_cash\", \"ending_cash\", \"candidate_contributions\",\n",
    "    \"individual_contributions\", \"unconvinced_pct\", \"phone_unweighted\", \"online_unweighted\", \"num_polls\",\n",
    "    \"unweighted_estimate\", \"unweighted_ci_lower\", \"unweighted_ci_upper\", \"weighted_estimate\",\n",
    "    \"weighted_ci_lower\", \"weighted_ci_upper\", \"white_pct\", \"black_pct\", \"asian_pct\", \"hispanic_pct\",\n",
    "    \"median_income\", \"impoverished_pct\", \"median_age\", \"renting_pct\", \"inflation\", \"isMidterm\",\n",
    "    \"genballot_predicted_margin\", \"genballot_predicted_lower\", \"genballot_predicted_upper\",\n",
    "    \"poll_fundamental_agree\",  'receipts_DEM', 'receipts_REP', 'disbursements_DEM', 'disbursements_REP'\n",
    "]\n",
    "\n",
    "num_quantiles = 3\n",
    "quantile_list = np.linspace(0.001, 0.999, num_quantiles)\n",
    "\n",
    "def entropy_loss(y_true, y_pred_quantiles) -> float:\n",
    "    #Convert quantile_list to a numpy array if it's not already one\n",
    "    quantile_array = np.array(quantile_list)\n",
    "    y_true = np.array(y_true)\n",
    "\n",
    "    # Calculate the absolute differences between y_true reshaped to (-1,1) and y_pred_quantiles\n",
    "    abs_diffs = np.abs(y_true[:, np.newaxis] - y_pred_quantiles)\n",
    "\n",
    "    # Find the index of the minimum difference for each prediction\n",
    "    min_indices = np.argmin(abs_diffs, axis=1)\n",
    "    \n",
    "\n",
    "    # Compute the negative log likelihood for the corresponding best quantile indices\n",
    "    losses = -np.log(quantile_array[min_indices]) - np.log(1 - quantile_array[min_indices])\n",
    "\n",
    "    # Return the mean of the losses\n",
    "    return np.mean(losses)**2\n",
    "\n",
    "def optima_model(model, param_dict, X, y, **kwargs):\n",
    "    \"\"\"Performs hyperparameter optimization for a a given bootstrapped X \n",
    "    ## Parameters:\n",
    "    model: sklearnable model. We use LGBMRegressor \n",
    "    param_dict: dictionary of hyperparameters to optimize\n",
    "    X: DataFrame with features\n",
    "    y: Series with target variable\"\"\"\n",
    "        \n",
    "    X_other, y_other = X.loc[X['year'] <= 2022, :], y.loc[X['year'] <= 2022]\n",
    "    \n",
    "    # Create fold structure so we can make a custom cross-validation for time-series\n",
    "    folds = [\n",
    "        (range(2002, 2012, 2), [2012, 2014]),\n",
    "        (range(2002, 2016, 2), [2016, 2018]),\n",
    "        (range(2002, 2020, 2), [2020, 2022])\n",
    "    ]\n",
    "\n",
    "    cv = CustomTimeSeriesCV(folds)\n",
    "        \n",
    "    #Preprocessing data: no need to scale data, because we use tree-based models which are monotonic-scale-invariant\n",
    "    #Because we don't need to scale data, we don't have to include the column transformer in the final saved model\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "        \n",
    "    def objective(params):\n",
    "        \"Function that takes in hyperparameters and returns loss, that Hyperopt will minimize.\"        \n",
    "        testing_loss = []\n",
    "        \n",
    "        for train_idx, test_idx in cv.split(X_other):\n",
    "            \n",
    "            quantile_predictions = np.zeros((len(test_idx), num_quantiles))\n",
    "            \n",
    "            for idx, quantile in enumerate(quantile_list):\n",
    "                pinball_scorer = make_scorer(mean_pinball_loss, greater_is_better=False, alpha = quantile)\n",
    "            \n",
    "                reg = model(**params, alpha = quantile)\n",
    "                pipe = Pipeline(steps = [\n",
    "                    ('preprocessing', preprocessor), \n",
    "                    ('model', reg)])\n",
    "                \n",
    "                \"\"\"Goes through each fold and calculates loss.\"\"\"\n",
    "                pipe.fit(X_other.iloc[train_idx], y_other.iloc[train_idx], model__eval_metric = pinball_scorer)\n",
    "                quantile_predictions[:, idx] = pipe.predict(X_other.iloc[test_idx])\n",
    "            testing_loss.append(entropy_loss(y_other.iloc[test_idx], quantile_predictions))   \n",
    "                      \n",
    "        return {'loss': np.mean(testing_loss), 'status': STATUS_OK}\n",
    "    \n",
    "    \"Hyperopt uses the TPE algorithm to optimize hyperparameters. We use the no_progress_loss function to stop early if we don't see progress.\"\n",
    "    best_params = fmin(fn=objective,\n",
    "                    space=param_dict,\n",
    "                    algo=tpe.suggest,\n",
    "                    trials=Trials(),\n",
    "                    early_stop_fn = no_progress_loss(2))\n",
    "                    \n",
    "                    \n",
    "    print(\"Best parameters pre-placing:\", best_params)\n",
    "    best_model = model(**best_params, **kwargs)\n",
    "    \n",
    "    for quantile in quantile_list:\n",
    "        \n",
    "        best_model.set_params(alpha = quantile)\n",
    "        pinball_scorer = make_scorer(mean_pinball_loss, greater_is_better=False, alpha = quantile)\n",
    "        pipe = Pipeline(steps = [('preprocessing', preprocessor),\n",
    "                             ('model', best_model)])\n",
    "        pipe.fit(X_other, y_other, model__eval_metric = pinball_scorer)\n",
    "        file_path = f\"../modelsv3/Pipe_{round(quantile, 3)}.pkl\"\n",
    "\n",
    "        # Open a file to write in binary mode????        \n",
    "        with open(file_path, 'wb') as file:\n",
    "            pkl.dump(pipe, file)\n",
    "            \n",
    "    #Returns the final model   \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9223372036854775807 [00:20<17505306707854429:17:52,  6.83s/trial, best loss: 3.456322873813134]\n",
      "Best parameters pre-placing: {'colsample_bytree': 0.7471697111374278, 'learning_rate': 0.0249855099331071, 'max_depth': 3, 'min_child_samples': 87, 'min_data_in_bin': 4, 'min_data_in_leaf': 8, 'n_estimators': 139, 'num_leaves': 21, 'reg_alpha': 0.09366183305548997, 'reg_lambda': 0.6116565752689745, 'subsample': 0.777189520958069, 'subsample_for_bin': 138426}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../cleaned_data/Engineered Dataset.csv\")\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "\n",
    "# Define the search space for Hyperopt\n",
    "param_dist_lgbm = {\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'quantile',\n",
    "    'num_leaves': hp.randint('num_leaves', 20, 70),  # Reduced the upper limit, \n",
    "    'n_estimators': hp.randint('n_estimators', 50, 200),  # Increased the range\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -2),  # Equivalent to about 0.0001 to 0.01\n",
    "    'subsample_for_bin': hp.randint('subsample_for_bin', 20000, 200000),  # Narrowed the range\n",
    "    'min_data_in_bin': hp.randint('min_data_in_bin', 1, 10), \n",
    "    'min_data_in_leaf': hp.randint('min_data_in_leaf', 1, 10),  # Reduced the upper limit\n",
    "    'min_child_samples': hp.randint('min_child_samples', 20, 150),  # Increased the range for more regularization\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.5),  # Increased upper limit for L1 regularization\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.5),  # Increased upper limit for L2 regularization\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8),  # Reduced the upper limit\n",
    "    'subsample': hp.uniform('subsample', 0.5, 0.8),  # Reduced the upper limit for more randomness\n",
    "    'max_depth': hp.randint('max_depth', 2, 10),  # Added max_depth for additional control\n",
    "    \"verbose\": -1,  # Keep verbose to -1 to reduce log clutter, \n",
    "}\n",
    "\n",
    "best_params = optima_model(lgb.LGBMRegressor, param_dist_lgbm, data.drop(columns=['margin']), data['margin'], \n",
    "                            boosting_type = 'dart', verbosity = -1, \n",
    "                            objective = 'quantile')\n",
    "\n",
    "with open(\"../modelsv3/best_params_in_general.pkl\", \"wb\") as f:\n",
    "    pkl.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cat__office_type_Governor  cat__office_type_House  \\\n",
      "0                          0.0                     0.0   \n",
      "1                          0.0                     0.0   \n",
      "2                          0.0                     0.0   \n",
      "3                          0.0                     0.0   \n",
      "4                          0.0                     0.0   \n",
      "..                         ...                     ...   \n",
      "457                        0.0                     0.0   \n",
      "458                        0.0                     0.0   \n",
      "459                        0.0                     0.0   \n",
      "460                        0.0                     0.0   \n",
      "461                        0.0                     0.0   \n",
      "\n",
      "     cat__office_type_President  cat__office_type_Senate  ord__final_rating  \\\n",
      "0                           0.0                      0.0          -1.476542   \n",
      "1                           0.0                      0.0          -1.484412   \n",
      "2                           0.0                      0.0          -1.482157   \n",
      "3                           0.0                      0.0          -1.484412   \n",
      "4                           0.0                      0.0           0.862817   \n",
      "..                          ...                      ...                ...   \n",
      "457                         0.0                      0.0          -4.373091   \n",
      "458                         0.0                      0.0          -2.313505   \n",
      "459                         0.0                      0.0          -4.333624   \n",
      "460                         0.0                      0.0           1.442500   \n",
      "461                         0.0                      0.0          -4.359233   \n",
      "\n",
      "     num__open_seat  num__incumbent_differential  num__special  \\\n",
      "0               0.0                          0.0           0.0   \n",
      "1               0.0                          0.0           0.0   \n",
      "2               0.0                          0.0           0.0   \n",
      "3               0.0                          0.0           0.0   \n",
      "4               0.0                          0.0           0.0   \n",
      "..              ...                          ...           ...   \n",
      "457             0.0                          0.0           0.0   \n",
      "458             0.0                          0.0           0.0   \n",
      "459             0.0                          0.0           0.0   \n",
      "460             0.0                          0.0           0.0   \n",
      "461             0.0                          0.0           0.0   \n",
      "\n",
      "     num__absenteeexcusereq  num__pollhours  ...  num__isMidterm  \\\n",
      "0                       0.0             0.0  ...             0.0   \n",
      "1                       0.0             0.0  ...             0.0   \n",
      "2                       0.0             0.0  ...             0.0   \n",
      "3                       0.0             0.0  ...             0.0   \n",
      "4                       0.0             0.0  ...             0.0   \n",
      "..                      ...             ...  ...             ...   \n",
      "457                     0.0             0.0  ...             0.0   \n",
      "458                     0.0             0.0  ...             0.0   \n",
      "459                     0.0             0.0  ...             0.0   \n",
      "460                     0.0             0.0  ...             0.0   \n",
      "461                     0.0             0.0  ...             0.0   \n",
      "\n",
      "     num__genballot_predicted_margin  num__genballot_predicted_lower  \\\n",
      "0                          -4.821299                      -11.068990   \n",
      "1                          -4.768927                      -10.970393   \n",
      "2                          -4.774294                      -10.994722   \n",
      "3                          -4.768927                      -10.973921   \n",
      "4                           4.838441                        9.354912   \n",
      "..                               ...                             ...   \n",
      "457                        -3.675894                       -8.411092   \n",
      "458                        -2.304123                       -5.957955   \n",
      "459                        -3.641747                       -8.362915   \n",
      "460                        -2.033536                       -5.031801   \n",
      "461                        -3.651593                       -8.321157   \n",
      "\n",
      "     num__genballot_predicted_upper  num__poll_fundamental_agree  \\\n",
      "0                         -1.269381                          0.0   \n",
      "1                         -1.269381                          0.0   \n",
      "2                         -1.269381                          0.0   \n",
      "3                         -1.269381                          0.0   \n",
      "4                          0.558608                          0.0   \n",
      "..                              ...                          ...   \n",
      "457                       -1.101632                          0.0   \n",
      "458                       -0.738392                          0.0   \n",
      "459                       -1.101632                          0.0   \n",
      "460                       -0.550972                          0.0   \n",
      "461                       -0.974501                          0.0   \n",
      "\n",
      "     num__receipts_DEM  num__receipts_REP  num__disbursements_DEM  \\\n",
      "0            -0.257613          -0.079202               -0.379015   \n",
      "1            -0.257613          -0.212306               -0.379015   \n",
      "2            -0.257613          -0.193382               -0.379015   \n",
      "3            -0.257613          -0.212306               -0.379015   \n",
      "4             0.276930           0.283765                0.188257   \n",
      "..                 ...                ...                     ...   \n",
      "457          -0.257613           0.050019               -0.219617   \n",
      "458          -0.190717           0.050019               -0.182444   \n",
      "459          -0.257613           0.050019               -0.219617   \n",
      "460          -0.104913           0.050019               -0.136712   \n",
      "461          -0.257613           0.050019               -0.219617   \n",
      "\n",
      "     num__disbursements_REP  expected value  \n",
      "0                 -0.159512        0.702687  \n",
      "1                 -0.164579        0.702687  \n",
      "2                 -0.159512        0.702687  \n",
      "3                 -0.164579        0.702687  \n",
      "4                  0.247767        0.702687  \n",
      "..                      ...             ...  \n",
      "457                0.045396        0.702687  \n",
      "458                0.045396        0.702687  \n",
      "459                0.045396        0.702687  \n",
      "460                0.045396        0.702687  \n",
      "461                0.045396        0.702687  \n",
      "\n",
      "[462 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../modelsv3/Pipe_0.5.pkl\", \"rb\") as f:\n",
    "    pipe1 = pkl.load(f)\n",
    "    \n",
    "X_2022 = data.loc[data['year'] == 2022].drop(columns = ['margin'])\n",
    "contributions = pipe1.predict(X_2022, pred_contrib = True)\n",
    "feature_names = pipe1.named_steps['preprocessing'].get_feature_names_out()\n",
    "\n",
    "contributions_df = pd.DataFrame(contributions, columns = np.append(feature_names, 'expected_value'))\n",
    "print(contributions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'descri_ber'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('^.*?__', '', 'ord__descri_ber')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
