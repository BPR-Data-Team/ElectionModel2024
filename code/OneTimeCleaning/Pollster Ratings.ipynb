{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost\n",
    "from scipy.stats import loguniform, randint, t\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Calculate Pollster Rating\n",
    "This project works in the following way:\n",
    "1. For every year, look at all polls from previous years\n",
    "2. Create a prediction algorithm from all non-pollster values (sample size, partisan, samplesize, days_before_election) and use them to predict the error via XGBoost\n",
    "3. Then, get the best model's predictions for each value, and place it back into the original dataset\n",
    "4. Calculate how much better each pollster is than what we'd expect from that pollster, given the other data points we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_estimator(X, y):\n",
    "    \"\"\"Runs through XGBoost to get the expected error based on non-pollster values (partisan, samplesize, etc.). \n",
    "    Returns the estimator that predicts that error the best.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "    \n",
    "    one_hot_fts = ['office_type', 'partisan']\n",
    "    std_fts = ['sample_size', 'days_before_election']\n",
    "    preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(), one_hot_fts),\n",
    "    ('std', StandardScaler(), std_fts)])\n",
    "    \n",
    "    cv = KFold(n_splits = 4)\n",
    "    xgb = xgboost.XGBRegressor()\n",
    "    model_name = xgb.__class__.__name__\n",
    "    \n",
    "    param_dict = {\n",
    "        'n_estimators': randint(10, 200), \n",
    "        'max_depth': randint(2, 12), \n",
    "        'eta': loguniform(0.001, 1), \n",
    "        'reg_alpha': loguniform(0.01, 100), \n",
    "        'reg_lambda': loguniform(0.01, 100)\n",
    "    }\n",
    "    \n",
    "    param_dict = {f\"{model_name.lower()}__{key}\": value for key, value in param_dict.items()}\n",
    "    \n",
    "    pipe = make_pipeline(preprocessor, xgb)\n",
    "    \n",
    "    grid = RandomizedSearchCV(pipe, param_distributions=param_dict, n_iter = 75, scoring='neg_mean_squared_error', cv = cv, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    #Code only used if I want to debug and see how good the model is doing\n",
    "    test_score = mean_absolute_error(y_test, grid.predict(X_test))\n",
    "    print(f\"Test MAE is {test_score}\")\n",
    "    \n",
    "    return (grid.best_estimator_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m     results \u001b[38;5;241m=\u001b[39m pollster_error_differential\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpollster_rating_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower_error_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(results)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mplus_minus_year\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_polls\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m, in \u001b[0;36mplus_minus_year\u001b[0;34m(before_year, pre_filtered_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m filtered_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#Getting error differentials for each pollster\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m previous_years\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected_error\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     24\u001b[0m previous_years\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_differential\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m previous_years[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected_error\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m previous_years[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mget_best_estimator\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_best_estimator\u001b[39m(X, y):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs through XGBoost to get the expected error based on non-pollster values (partisan, samplesize, etc.). \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Returns the estimator that predicts that error the best.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     one_hot_fts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffice_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpartisan\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m     std_fts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_before_election\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/data1030/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2277\u001b[0m     )\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "#HYPERPARAMETERS:\n",
    "years_to_rate = 10\n",
    "\n",
    "def conf_width(errors):\n",
    "        \"\"\"Calculates the length of the one-sided 95% conf interval, based on student's t-distribution.\"\"\"\n",
    "        if len(errors) == 1:\n",
    "                return np.inf\n",
    "        else:\n",
    "                return (t.ppf(0.95, len(errors) - 1) * np.std(errors) / np.sqrt(len(errors)))\n",
    "\n",
    "def plus_minus_year(before_year, pre_filtered_data):\n",
    "    \"\"\"For a given year, returns values for expected error for every poll, based on all years before that year\"\"\"\n",
    "    #takes only the years and columns we care about\n",
    "    previous_years = pre_filtered_data.loc[(pre_filtered_data['year'] < before_year) & (pre_filtered_data['year'] >= before_year - years_to_rate), :]\n",
    "    \n",
    "    filtered_data = previous_years.loc[:, ['office_type', 'partisan', 'sample_size', 'days_before_election', 'error']]\n",
    "    \n",
    "    X = filtered_data.drop(columns=['error'])\n",
    "    y = filtered_data['error']\n",
    "    \n",
    "    #Getting error differentials for each pollster\n",
    "    estimator = get_best_estimator(X, y)\n",
    "    previous_years.loc[:, 'expected_error'] = estimator.predict(X)\n",
    "    previous_years.loc[:, 'error_differential'] = previous_years['expected_error'] - previous_years['error']\n",
    "    \n",
    "    pollster_error_differential = previous_years.groupby([\"pollster_rating_id\"], as_index=False).agg({'error_differential': [conf_width, 'mean', 'count'], \n",
    "                                                                                                                  'bias': 'mean'})\n",
    "    \n",
    "    #Calculating info relating to error differentials\n",
    "    pollster_error_differential.columns = [\"pollster_rating_id\", \"error_differential_conf\", \"error_differential_mean\", 'count', 'mean_bias']\n",
    "    #Getting the lower bound for error differential, based on the confidence interval and mean\n",
    "    pollster_error_differential['lower_error_diff'] = pollster_error_differential[\"error_differential_mean\"] - pollster_error_differential[\"error_differential_conf\"]\n",
    "    #Check if a pollster is valid yes or no    \n",
    "    pollster_error_differential['valid'] = pollster_error_differential['count'] >= 10\n",
    "    pollster_error_differential['year'] = before_year\n",
    "    \n",
    "    results = pollster_error_differential.loc[:, ['year', 'pollster_rating_id', \"lower_error_diff\", \"mean_bias\", \"count\", \"valid\"]]\n",
    "    \n",
    "    return(results)\n",
    "\n",
    "plus_minus_year(2020, past_polls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_polls = pd.read_csv('../../cleaned_data/PollsforRating.csv')\n",
    "#full_pollster_ratings = pd.concat([plus_minus_year(year, past_polls) for year in [2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018, 2020, 2022, 2024]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking Pollsters within each year and valid/not, and then publishing full data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_pollster_ratings['rank'] = full_pollster_ratings.groupby(['year', 'valid'])['lower_error_diff'].rank('min', ascending=False)\n",
    "full_pollster_ratings.to_csv(\"../../cleaned_data/Pollster Ratings.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
