{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "class CustomTimeSeriesCV(BaseCrossValidator):\n",
    "    \"\"\"Creates an iterator that contains the indices from each dataset based on the years given\"\"\"\n",
    "    def __init__(self, years):\n",
    "        self.years = years\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for train_years, test_years in self.years:\n",
    "            train_indices = np.where(X['cycle'].isin(train_years))[0]\n",
    "            test_indices = np.where(X['cycle'].isin(test_years))[0]\n",
    "            yield train_indices, test_indices\n",
    "        \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(self.years) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_polls = pd.read_csv('../../data/raw_polls.csv')\n",
    "days_to_rate = 50\n",
    "\n",
    "office_type_dict = {\n",
    "    \"Pres-G\": \"President\",\n",
    "    \"Sen-G\": \"Senate\",\n",
    "    \"Gov-G\": \"Governor\",\n",
    "    \"House-G\": \"House\"    \n",
    "}\n",
    "\n",
    "#This filters out rows we do not want\n",
    "past_polls = past_polls.query(\"time_to_election <= @days_to_rate & not @pd.isna(methodology)\") #Filtering out rows with no methodology\n",
    "past_polls = past_polls[(past_polls['cand1_party'] == \"DEM\") & (past_polls['cand2_party'] == \"REP\") & (past_polls['location'] != \"US\")]\n",
    "past_polls = past_polls[past_polls['type_simple'].isin([\"Pres-G\", \"Sen-G\", \"Gov-G\", \"House-G\"])]\n",
    "\n",
    "#Adding important columns, X and Y\n",
    "past_polls['office_type'] = past_polls['type_simple'].map(office_type_dict)\n",
    "past_polls['bias'] = past_polls['margin_poll'] - past_polls['margin_actual']\n",
    "past_polls['squared_error'] = np.square(past_polls['bias']) \n",
    "\n",
    "past_polls = past_polls[['cycle', 'office_type', 'pollster_rating_id', 'time_to_election', 'methodology', \n",
    "                                     'partisan', 'samplesize', 'margin_poll', 'bias', 'squared_error']]\n",
    "\n",
    "#Polls often have multiple methodologies, so we will split them into multiple columns\n",
    "unique_methods = set()\n",
    "for methods in past_polls['methodology']:\n",
    "    unique_methods.update(methods.split('/'))\n",
    "\n",
    "for method in unique_methods:\n",
    "    past_polls[method] = past_polls['methodology'].apply(lambda x: 1 if method in x.split('/') else 0)\n",
    "\n",
    "#Removes methodology column, as it is no longer needed\n",
    "past_polls = past_polls.drop(columns=['methodology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pollster_rating_model(poll_df, before_year, model, param_dist):\n",
    "    \"\"\"This creates and saves two models for polls before a given year: one to predict error, one to predict bias.\n",
    "    It is very important that we do NOT include polls from the before year in the data\n",
    "    The before year is the year that we will eventually use to run the model on -- our current model is based on 2024\"\"\"\n",
    "    poll_df = poll_df[poll_df['cycle'] < before_year]\n",
    "    X = poll_df.drop(columns=['bias', 'squared_error'])\n",
    "    error = poll_df['squared_error']\n",
    "    bias = poll_df['bias']\n",
    "    \n",
    "    pollster_dummies = OneHotEncoder(sparse_output=False, handle_unknown='ignore', min_frequency=20) #Only choosing pollster with 20 or more previous polls\n",
    "\n",
    "    preprocessor = ColumnTransformer([('cat1', pollster_dummies, ['pollster_rating_id'], ), \n",
    "                                      ('cat2', OneHotEncoder(handle_unknown='ignore'), ['partisan', 'office_type'])], remainder='passthrough')\n",
    "\n",
    "    min_year = poll_df['cycle'].min() #The minimum year in the dataset, we choose to include polls going back to 1998\n",
    "    \n",
    "    folds = [(range(min_year, year, 2), [year]) for year in range(min_year + 2, before_year, 2)] #Dynamically creating folds based on the before year\n",
    "    cv = CustomTimeSeriesCV(folds)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    param_dist = {\n",
    "    'regressor__' + key: value for key, value in param_dist.items()\n",
    "    }\n",
    "    \n",
    "    error_grid = RandomizedSearchCV(model, param_dist, n_iter=50, cv=cv, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1, verbose = 1)\n",
    "    error_grid.fit(X, error)\n",
    "    print(\"Percent predictions of error < 0 are: \"+ str(np.mean(error_grid.predict(X) < 0)))\n",
    "    \n",
    "    #The error model will have significantly higher MSE than the bias model, as the error model is predicting the squared error\n",
    "    print(f'Best error model for {before_year}: {model[-1].__class__.__name__} with MSE of {error_grid.best_score_}')\n",
    "    \n",
    "    file_path_error = f'../../models/Polls_{before_year}_error.pkl'\n",
    "    with open(file_path_error, 'wb') as file:\n",
    "        pkl.dump(error_grid, file)\n",
    "\n",
    "    bias_grid = RandomizedSearchCV(model, param_dist, n_iter=50, cv=cv, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1, verbose = 1)\n",
    "    bias_grid.fit(X, bias)\n",
    "    file_path_bias = f'../../models/Polls_{before_year}_bias.pkl'\n",
    "    with open(file_path_bias, 'wb') as file:\n",
    "        pkl.dump(bias_grid, file)\n",
    "        \n",
    "    print(f'Best bias model for {before_year}: {model[-1].__class__.__name__} with MSE of {bias_grid.best_score_}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2002: SVR with MSE of -3939.338061169812\n",
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n",
      "Best bias model for 2002: SVR with MSE of -45.914608298151165\n",
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2004: SVR with MSE of -4381.136016250903\n",
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best bias model for 2004: SVR with MSE of -57.64040999892533\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2006: SVR with MSE of -3765.6988462145614\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best bias model for 2006: SVR with MSE of -49.552334112236395\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2008: SVR with MSE of -4659.989791479662\n",
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "Best bias model for 2008: SVR with MSE of -49.25629510179311\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2010: SVR with MSE of -4509.088251294272\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best bias model for 2010: SVR with MSE of -46.10944796049729\n",
      "Fitting 6 folds for each of 50 candidates, totalling 300 fits\n",
      "Percent predictions of error < 0 are: 0.0010466820180029307\n",
      "Best error model for 2012: SVR with MSE of -6042.49057122284\n",
      "Fitting 6 folds for each of 50 candidates, totalling 300 fits\n",
      "Best bias model for 2012: SVR with MSE of -47.944193244164126\n",
      "Fitting 7 folds for each of 50 candidates, totalling 350 fits\n",
      "Percent predictions of error < 0 are: 0.0006785411365564037\n",
      "Best error model for 2014: SVR with MSE of -5782.201964608203\n",
      "Fitting 7 folds for each of 50 candidates, totalling 350 fits\n",
      "Best bias model for 2014: SVR with MSE of -45.82691224362526\n",
      "Fitting 8 folds for each of 50 candidates, totalling 400 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2016: SVR with MSE of -6392.942744035407\n",
      "Fitting 8 folds for each of 50 candidates, totalling 400 fits\n",
      "Best bias model for 2016: SVR with MSE of -47.93978435103345\n",
      "Fitting 9 folds for each of 50 candidates, totalling 450 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2018: SVR with MSE of -6451.775560732558\n",
      "Fitting 9 folds for each of 50 candidates, totalling 450 fits\n",
      "Best bias model for 2018: SVR with MSE of -48.90127554304928\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2020: SVR with MSE of -6545.931825366493\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "Best bias model for 2020: SVR with MSE of -48.437243195561926\n",
      "Fitting 11 folds for each of 50 candidates, totalling 550 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asherlabovich/miniconda3/envs/data1030/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2022: SVR with MSE of -6417.210568822541\n",
      "Fitting 11 folds for each of 50 candidates, totalling 550 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asherlabovich/miniconda3/envs/data1030/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best bias model for 2022: SVR with MSE of -48.12301416698863\n",
      "Fitting 12 folds for each of 50 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asherlabovich/miniconda3/envs/data1030/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent predictions of error < 0 are: 0.0\n",
      "Best error model for 2024: SVR with MSE of -6542.50547910147\n",
      "Fitting 12 folds for each of 50 candidates, totalling 600 fits\n",
      "Best bias model for 2024: SVR with MSE of -47.965269706871545\n"
     ]
    }
   ],
   "source": [
    "years = range(2002, 2026, 2)\n",
    "\n",
    "param_dist_svr = {\n",
    "    'C': loguniform(1e-3, 1e3),  # Regularization parameter\n",
    "    'degree': randint(2, 6),  # Degree of the polynomial kernel function (only relevant if kernel='poly')\n",
    "    'gamma': loguniform(1e-4, 1e1),  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    'coef0': uniform(0, 1),  # Independent term in kernel function (only relevant for 'poly' and 'sigmoid')\n",
    "    'tol': loguniform(1e-5, 1e-1),  # Tolerance for stopping criterion\n",
    "}\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    make_pollster_rating_model(past_polls, year, SVR(), param_dist_svr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
