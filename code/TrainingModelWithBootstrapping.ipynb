{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "import re\n",
    "import pickle as pkl\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from hyperopt.pyll.base import Apply\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "#Creating a custom time series cross-validator\n",
    "class CustomTimeSeriesCV(BaseCrossValidator):\n",
    "    \"\"\"Creates an iterator that contains the indices from each dataset based on the years given\"\"\"\n",
    "    def __init__(self, years):\n",
    "        self.years = years\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for train_years, test_years in self.years:\n",
    "            train_indices = np.where(X['year'].isin(train_years))[0]\n",
    "            test_indices = np.where(X['year'].isin(test_years))[0]\n",
    "            yield train_indices, test_indices\n",
    "        \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(self.years) \n",
    "    \n",
    "#Bootstraps X and y\n",
    "def bootstrap(group, n=None):\n",
    "    if n is None:\n",
    "        n = len(group)\n",
    "    return group.sample(n, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "#Categorical features that need to be one-hot encoded    \n",
    "one_hot_fts = ['office_type']\n",
    "\n",
    "#Rating is the only ordinal feature\n",
    "ordinal_fts = ['final_rating']\n",
    "\n",
    "#Rating is the only ordinal feature\n",
    "ordinal_fts = ['final_rating']\n",
    "ordinal_fts_ranking = ['Safe R', 'Likely R', 'Leans R', 'Toss-up', 'Leans D', 'Likely D', 'Safe D']\n",
    "\n",
    "#Cont features that should be pass-throughed (and later scaled)\n",
    "cont_fts = [\n",
    "    \"open_seat\", \"incumbent_differential\", \"special\", \"absenteeexcusereq\", \"pollhours\", \"avgpollhours\", \"minpollhours\",\n",
    "    \"regdeadlines\", \"voteridlaws\", \"novoterid\", \"noallmailvote\", \"noearlyvote\", \"nofelonreg\",\n",
    "    \"nofelonsregafterincar\", \"nonstrictid\", \"nonstrictphoto\", \"nopollplacereg\", \"nopr\", \"nosamedayreg\",\n",
    "    \"nostateholiday\", \"pr16\", \"pr17\", \"pr175\", \"pr60\", \"pr90\", \"strictid\", \"strictphoto\", \"covi_num\",\n",
    "    \"prev_dem_gen_tp\", \"prev_gen_margin\", \"weighted_genpoll\", \"weighted_genpoll_lower\",\n",
    "    \"weighted_genpoll_upper\", \"unweighted_genpoll\", \"mean_specials_differential\", \n",
    "    \"house_chamber_margin\", \"senate_chamber_margin\", \"previous_cci\", \"current_cci\", \"change_cci\",\n",
    "    \"previous_gas\", \"current_gas\", \"change_gas\", \"previous_unemployment\", \"current_unemployment\",\n",
    "    \"change_unemployment\",  \"receipts\", \"from_committee_transfers\", \"disbursements\",\n",
    "    \"to_committee_transfers\", \"beginning_cash\", \"ending_cash\", \"candidate_contributions\",\n",
    "    \"individual_contributions\", \"unconvinced_pct\", \"phone_unweighted\", \"online_unweighted\", \"num_polls\",\n",
    "    \"unweighted_estimate\", \"unweighted_ci_lower\", \"unweighted_ci_upper\", \"weighted_estimate\",\n",
    "    \"weighted_ci_lower\", \"weighted_ci_upper\", \"white_pct\", \"black_pct\", \"asian_pct\", \"hispanic_pct\",\n",
    "    \"median_income\", \"impoverished_pct\", \"median_age\", \"renting_pct\", \"inflation\", \"isMidterm\",\n",
    "    \"genballot_predicted_margin\", \"genballot_predicted_lower\", \"genballot_predicted_upper\",\n",
    "    \"poll_fundamental_agree\",  'receipts_DEM', 'receipts_REP', 'disbursements_DEM', 'disbursements_REP', \n",
    "    'average_genballot', 'genballot_individual_predicted_margin', 'genballot_campaign5_predicted_margin', \n",
    "    'genballot_campaign10_predicted_margin', 'genballot_campaign15_predicted_margin', \n",
    "    'average_genballot_predicted_margin', 'expert_rating_democrat', 'finance_fundamental_agree'\n",
    "]\n",
    "\n",
    "def optima_model(model, param_dict, data, **kwargs):\n",
    "    \"\"\"Performs hyperparameter optimization for a a given model, keeping track of loss. \n",
    "    ## Parameters:\n",
    "    model: sklearnable model, like XGBoost or Linreg\n",
    "    param_dict: dictionary of hyperparameters to optimize\n",
    "    X: DataFrame with features\n",
    "    y: Series with target variable\"\"\"\n",
    "\n",
    "    train, _ = data.loc[data['year'] < 2022], data.loc[data['year'] == 2022]\n",
    "\n",
    "    # Create fold structure so we can make a custom cross-validation for time-series\n",
    "    folds = [\n",
    "        (range(2002, 2010, 2), [2010, 2012]),\n",
    "        (range(2002, 2014, 2), [2014, 2016]),\n",
    "        (range(2002, 2018, 2), [2018, 2020])\n",
    "    ]\n",
    "\n",
    "    cv = CustomTimeSeriesCV(folds)\n",
    "        \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "    \n",
    "    def objective(params):\n",
    "        \"Function that takes in hyperparameters and returns loss, that Hyperopt will minimize.\"        \n",
    "        testing_loss = []\n",
    "        accuracies = []\n",
    "        for train_idx, test_idx in cv.split(train):\n",
    "            bootstrapped_train = train.iloc[train_idx].groupby(['year', 'office_type']).apply(bootstrap)\n",
    "            X_train = bootstrapped_train.drop(columns = ['margin'])\n",
    "            y_train = bootstrapped_train['margin']\n",
    "            X_test = train.iloc[test_idx].drop(columns = ['margin'])\n",
    "            y_test = train.iloc[test_idx]['margin']\n",
    "                   \n",
    "            reg = model(**params)\n",
    "            pipe = Pipeline(steps = [\n",
    "                ('preprocessing', preprocessor), \n",
    "                ('model', reg)])\n",
    "                                    \n",
    "            \"\"\"Goes through each fold and calculates loss.\"\"\"\n",
    "            pipe.fit(X_train, y_train)\n",
    "            \n",
    "            predictions = pipe.predict(X_test)\n",
    "            testing_loss.append(mean_squared_error(y_test, predictions, squared=False))\n",
    "            accuracies.append(accuracy_score(np.sign(y_test), np.sign(predictions)))\n",
    "            \n",
    "        return {'loss': np.mean(testing_loss), 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "    \"Hyperopt uses the TPE algorithm to optimize hyperparameters. We use the no_progress_loss function to stop early if we don't see progress.\"\n",
    "    best_params = fmin(fn=objective,\n",
    "                    space=param_dict,\n",
    "                    algo=tpe.suggest,\n",
    "                    trials=Trials(),\n",
    "                    early_stop_fn=no_progress_loss(10))\n",
    "                    \n",
    "    model = model(**best_params, **kwargs)\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('preprocessing', preprocessor), \n",
    "        ('model', model)])\n",
    "    \n",
    "    #Training final model on data prior to and including 2022, so we get the full extent of the data!\n",
    "    X, y = data.loc[data['year'] <= 2022, :].drop(columns = ['margin']), data.loc[data['year'] <= 2022, :]['margin']\n",
    "    \n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/9223372036854775807 [03:06<19960366440573926:58:08,  7.79s/trial, best loss: 8.29199760499154] \n",
      "{'boosting_type': 'dart', 'class_weight': None, 'colsample_bytree': 0.7923653309626872, 'importance_type': 'split', 'learning_rate': 0.13080112759759152, 'max_depth': 8, 'min_child_samples': 119, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 154, 'n_jobs': 8, 'num_leaves': 62, 'objective': None, 'random_state': None, 'reg_alpha': 0.2376508807142858, 'reg_lambda': 1.356730343882979, 'subsample': 0.7614484692144594, 'subsample_for_bin': 187457, 'subsample_freq': 0, 'drop_rate': 0.4455668539679096, 'min_data_in_bin': 8, 'min_data_in_leaf': 8, 'skip_drop': 0.5528202167808689, 'monotone_constraints': [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'verbosity': -1}\n",
      "  0%|          | 12/9223372036854775807 [01:36<20613363011239571:54:40,  8.05s/trial, best loss: 8.590772822751525]\n",
      "{'boosting_type': 'dart', 'class_weight': None, 'colsample_bytree': 0.5562343590022419, 'importance_type': 'split', 'learning_rate': 0.13385748272740744, 'max_depth': 8, 'min_child_samples': 82, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 148, 'n_jobs': 8, 'num_leaves': 35, 'objective': None, 'random_state': None, 'reg_alpha': 0.19985787222796947, 'reg_lambda': 1.2536145897123834, 'subsample': 0.7164285555382973, 'subsample_for_bin': 22572, 'subsample_freq': 0, 'drop_rate': 0.18294215503396666, 'min_data_in_bin': 3, 'min_data_in_leaf': 2, 'skip_drop': 0.6401308564820545, 'monotone_constraints': [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'verbosity': -1}\n",
      "  0%|          | 32/9223372036854775807 [04:25<21226020930915459:58:56,  8.28s/trial, best loss: 8.60417584274972] \n",
      "{'boosting_type': 'dart', 'class_weight': None, 'colsample_bytree': 0.7996306300105509, 'importance_type': 'split', 'learning_rate': 0.10170973417970469, 'max_depth': 7, 'min_child_samples': 147, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 138, 'n_jobs': 8, 'num_leaves': 27, 'objective': None, 'random_state': None, 'reg_alpha': 1.029516938369316, 'reg_lambda': 1.3470257792234894, 'subsample': 0.6451624281786952, 'subsample_for_bin': 54123, 'subsample_freq': 0, 'drop_rate': 0.22632779405326575, 'min_data_in_bin': 7, 'min_data_in_leaf': 1, 'skip_drop': 0.7644797738900773, 'monotone_constraints': [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'verbosity': -1}\n",
      "  0%|          | 17/9223372036854775807 [02:22<21453855714100387:50:24,  8.37s/trial, best loss: 8.426179142536386]\n",
      "{'boosting_type': 'dart', 'class_weight': None, 'colsample_bytree': 0.5937989603610899, 'importance_type': 'split', 'learning_rate': 0.09272136478762594, 'max_depth': 9, 'min_child_samples': 64, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 183, 'n_jobs': 8, 'num_leaves': 46, 'objective': None, 'random_state': None, 'reg_alpha': 1.1796325375555203, 'reg_lambda': 1.260299364862406, 'subsample': 0.6434631255893353, 'subsample_for_bin': 51087, 'subsample_freq': 0, 'drop_rate': 0.19833201334836006, 'min_data_in_bin': 5, 'min_data_in_leaf': 8, 'skip_drop': 0.5882835394873068, 'monotone_constraints': [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'verbosity': -1}\n",
      "  0%|          | 14/9223372036854775807 [01:17<14137503624586667:48:16,  5.52s/trial, best loss: 8.602661500024086]\n",
      "{'boosting_type': 'dart', 'class_weight': None, 'colsample_bytree': 0.4945609898822393, 'importance_type': 'split', 'learning_rate': 0.06403812932974831, 'max_depth': 6, 'min_child_samples': 48, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 181, 'n_jobs': 8, 'num_leaves': 62, 'objective': None, 'random_state': None, 'reg_alpha': 0.49327263057932413, 'reg_lambda': 0.04057337903389319, 'subsample': 0.559288912250084, 'subsample_for_bin': 35621, 'subsample_freq': 0, 'drop_rate': 0.40280773461249086, 'min_data_in_bin': 8, 'min_data_in_leaf': 9, 'skip_drop': 0.8320717305960668, 'monotone_constraints': [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'verbosity': -1}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../cleaned_data/Engineered Dataset.csv\")\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "\n",
    "names_for_monotonicity = preprocessor.fit(data.drop(columns=['margin'])).get_feature_names_out()\n",
    "before_processing_monotonic_columns = ['incumbent_differential', 'receipts', 'disbursements', \n",
    "                                       'genballot_predicted_margin', 'specials_predicted_margin', 'unweighted_estimate', 'unweighted_ci_lower',\n",
    "                                       'unweighted_ci_upper','weighted_estimate', 'weighted_ci_lower', 'weighted_ci_upper',\n",
    "                                       'phone_unweighted', 'online_unweighted', 'receipts_genballot_interaction',\n",
    "                                       'disbursements_genballot_interaction', 'poll_fundamental_average']\n",
    "\n",
    "monotonic_columns = ['num__' + name for name in before_processing_monotonic_columns] + ['ord__final_rating']\n",
    "monotone_constraints = [1 if name in monotonic_columns else 0 for name in names_for_monotonicity]\n",
    "\n",
    "# Define the search space for Hyperopt\n",
    "param_dist_lgbm = {\n",
    "    'boosting_type': 'dart',\n",
    "    'num_leaves': hp.randint('num_leaves', 20, 70),  # Reduced the upper limit, \n",
    "    'n_estimators': hp.randint('n_estimators', 50, 200),  # Increased the range\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -2),  # Equivalent to about 0.0001 to 0.01\n",
    "    'subsample_for_bin': hp.randint('subsample_for_bin', 20000, 200000),  # Narrowed the range\n",
    "    'min_data_in_bin': hp.randint('min_data_in_bin', 1, 10), \n",
    "    'min_data_in_leaf': hp.randint('min_data_in_leaf', 1, 10),  # Reduced the upper limit\n",
    "    'min_child_samples': hp.randint('min_child_samples', 20, 150),  # Increased the range for more regularization\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.5),  # Increased upper limit for L1 regularization\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.5),  # Increased upper limit for L2 regularization\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.8),  # Reduced the upper limit\n",
    "    'subsample': hp.uniform('subsample', 0.5, 0.8),  # Reduced the upper limit for more randomness\n",
    "    'max_depth': hp.randint('max_depth', 2, 10),  # Added max_depth for additional control\n",
    "    'drop_rate': hp.uniform('drop_rate', 0.05, 0.5),  # Added drop_rate for dart\n",
    "    'skip_drop': hp.uniform('skip_drop', 0.1, 0.9),  # Added skip_drop for dart\n",
    "    \"verbose\": -1,  # Keep verbose to -1 to reduce log clutter,  \n",
    "    'monotone_constraints': monotone_constraints, \n",
    "    'n_jobs': 8\n",
    "}\n",
    "\n",
    "num_trials = 10\n",
    "for idx in range(num_trials):\n",
    "    \n",
    "    trained_lgbm = optima_model(lgb.LGBMRegressor, param_dist_lgbm, data,\n",
    "                                boosting_type = 'dart', monotone_constraints = monotone_constraints, verbosity = -1, \n",
    "                                n_jobs = 8)\n",
    "    print(trained_lgbm.named_steps['model'].get_params())\n",
    "    \n",
    "    file_path = f\"../bootstrapped_models_testing/Model_{idx}.pkl\"\n",
    "\n",
    "    # Open a file to write in binary mode????        \n",
    "    with open(file_path, 'wb') as file:\n",
    "        pkl.dump(trained_lgbm, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat__office_type_Governor' 'cat__office_type_House'\n",
      " 'cat__office_type_President' 'cat__office_type_Senate'\n",
      " 'ord__final_rating' 'num__open_seat' 'num__incumbent_differential'\n",
      " 'num__special' 'num__absenteeexcusereq' 'num__pollhours'\n",
      " 'num__avgpollhours' 'num__minpollhours' 'num__regdeadlines'\n",
      " 'num__voteridlaws' 'num__novoterid' 'num__noallmailvote'\n",
      " 'num__noearlyvote' 'num__nofelonreg' 'num__nofelonsregafterincar'\n",
      " 'num__nonstrictid' 'num__nonstrictphoto' 'num__nopollplacereg'\n",
      " 'num__nopr' 'num__nosamedayreg' 'num__nostateholiday' 'num__pr16'\n",
      " 'num__pr17' 'num__pr175' 'num__pr60' 'num__pr90' 'num__strictid'\n",
      " 'num__strictphoto' 'num__covi_num' 'num__prev_dem_gen_tp'\n",
      " 'num__prev_gen_margin' 'num__weighted_genpoll'\n",
      " 'num__weighted_genpoll_lower' 'num__weighted_genpoll_upper'\n",
      " 'num__unweighted_genpoll' 'num__mean_specials_differential'\n",
      " 'num__house_chamber_margin' 'num__senate_chamber_margin'\n",
      " 'num__previous_cci' 'num__current_cci' 'num__change_cci'\n",
      " 'num__previous_gas' 'num__current_gas' 'num__change_gas'\n",
      " 'num__previous_unemployment' 'num__current_unemployment'\n",
      " 'num__change_unemployment' 'num__receipts'\n",
      " 'num__from_committee_transfers' 'num__disbursements'\n",
      " 'num__to_committee_transfers' 'num__beginning_cash' 'num__ending_cash'\n",
      " 'num__candidate_contributions' 'num__individual_contributions'\n",
      " 'num__unconvinced_pct' 'num__phone_unweighted' 'num__online_unweighted'\n",
      " 'num__num_polls' 'num__unweighted_estimate' 'num__unweighted_ci_lower'\n",
      " 'num__unweighted_ci_upper' 'num__weighted_estimate'\n",
      " 'num__weighted_ci_lower' 'num__weighted_ci_upper' 'num__white_pct'\n",
      " 'num__black_pct' 'num__asian_pct' 'num__hispanic_pct'\n",
      " 'num__median_income' 'num__impoverished_pct' 'num__median_age'\n",
      " 'num__renting_pct' 'num__inflation' 'num__isMidterm'\n",
      " 'num__genballot_predicted_margin' 'num__genballot_predicted_lower'\n",
      " 'num__genballot_predicted_upper' 'num__poll_fundamental_agree'\n",
      " 'num__receipts_DEM' 'num__receipts_REP' 'num__disbursements_DEM'\n",
      " 'num__disbursements_REP' 'num__average_genballot'\n",
      " 'num__genballot_individual_predicted_margin'\n",
      " 'num__genballot_campaign5_predicted_margin'\n",
      " 'num__genballot_campaign10_predicted_margin'\n",
      " 'num__genballot_campaign15_predicted_margin'\n",
      " 'num__average_genballot_predicted_margin' 'num__expert_rating_democrat'\n",
      " 'num__finance_fundamental_agree']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../cleaned_data/Engineered Dataset.csv\")\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), one_hot_fts),\n",
    "        ('ord', OrdinalEncoder(categories = [ordinal_fts_ranking], handle_unknown='use_encoded_value', \n",
    "                               unknown_value=np.nan), ordinal_fts),\n",
    "        ('num', 'passthrough', cont_fts)])\n",
    "\n",
    "names_for_monotonicity = preprocessor.fit(data.drop(columns=['margin'])).get_feature_names_out()\n",
    "print(names_for_monotonicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  3., 24., 81., 17.,  6.,  3.,  9.,  5.,  1.]),\n",
       " array([ 85. , 124.3, 163.6, 202.9, 242.2, 281.5, 320.8, 360.1, 399.4,\n",
       "        438.7, 478. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiGElEQVR4nO3dbXCU1d3H8d/Kw5posorCblICxLpaIUIdcCLxISmaTBEpTlqrQi0MbQcMWCNtkZhaQ6duMLaZWNPiYDs0jk3xRcE6RTGxahgnZRqeKo0O2jFCVLYZbdyNJCYFzv2CyXWzhAc3bE64lu9n5sy45zq7+f/nlO5vzl7JeowxRgAAAJacN9wFAACAcwvhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVI4e7gOMdOXJEH330kdLS0uTxeIa7HAAA8AUYY9TV1aXMzEydd96pzzbOuvDx0UcfKSsra7jLAAAAg9De3q7x48efcs1ZFz7S0tIkHS0+PT19mKsBAABfRDQaVVZWlvM+fipnXfjo/6glPT2d8AEAgMt8kVsmuOEUAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWjYxn8aFDh1RRUaE//vGPCofDysjI0KJFi/TTn/5U5513NMcYY7R69WqtW7dOnZ2dys3N1W9+8xtNmTJlSBoAEmXSqs3DXULc3l8zZ7hLAIC4xXXy8dhjj+mpp55SbW2t3n77bVVVVenxxx/Xk08+6aypqqpSdXW1amtr1dLSokAgoMLCQnV1dSW8eAAA4D5xhY+///3vmjdvnubMmaNJkybpW9/6loqKirR9+3ZJR089ampqVF5eruLiYuXk5Kiurk7d3d2qr68fkgYAAIC7xBU+brjhBv3tb3/TO++8I0n65z//qTfeeEO33nqrJKmtrU3hcFhFRUXOc7xer/Lz89Xc3JzAsgEAgFvFdc/Hgw8+qEgkoq985SsaMWKEDh8+rEcffVR33323JCkcDkuS/H5/zPP8fr/27dt3wtfs7e1Vb2+v8zgajcbVAAAAcJe4Tj6ee+45Pfvss6qvr9fOnTtVV1enX/7yl6qrq4tZ5/F4Yh4bYwbM9ausrJTP53NGVlZWnC0AAAA3iSt8/OQnP9GqVat011136eqrr9Y999yjBx54QJWVlZKkQCAg6f9PQPp1dHQMOA3pV1ZWpkgk4oz29vbB9AEAAFwirvDR3d3t/EptvxEjRujIkSOSpOzsbAUCATU2NjrX+/r61NTUpLy8vBO+ptfrVXp6eswAAADJK657PubOnatHH31UEyZM0JQpU7Rr1y5VV1dr8eLFko5+3FJaWqpQKKRgMKhgMKhQKKTU1FTNnz9/SBoAAADuElf4ePLJJ/Xwww+rpKREHR0dyszM1JIlS/Szn/3MWbNy5Ur19PSopKTE+SNjDQ0NSktLS3jxAADAfTzGGDPcRRwrGo3K5/MpEonwEQys4i+cAsDgxfP+zXe7AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKviCh+TJk2Sx+MZMJYtWyZJMsaooqJCmZmZSklJUUFBgVpbW4ekcAAA4E5xhY+WlhYdOHDAGY2NjZKkO+64Q5JUVVWl6upq1dbWqqWlRYFAQIWFherq6kp85QAAwJXiCh9jx45VIBBwxl//+ld9+ctfVn5+vowxqqmpUXl5uYqLi5WTk6O6ujp1d3ervr5+qOoHAAAuM+h7Pvr6+vTss89q8eLF8ng8amtrUzgcVlFRkbPG6/UqPz9fzc3NJ32d3t5eRaPRmAEAAJLXoMPH888/r08//VSLFi2SJIXDYUmS3++PWef3+51rJ1JZWSmfz+eMrKyswZYEAABcYNDh4/e//71mz56tzMzMmHmPxxPz2BgzYO5YZWVlikQizmhvbx9sSQAAwAVGDuZJ+/bt0yuvvKKNGzc6c4FAQNLRE5CMjAxnvqOjY8BpyLG8Xq+8Xu9gygAAAC40qJOP9evXa9y4cZozZ44zl52drUAg4PwGjHT0vpCmpibl5eWdeaUAACApxH3yceTIEa1fv14LFy7UyJH//3SPx6PS0lKFQiEFg0EFg0GFQiGlpqZq/vz5CS0aAAC4V9zh45VXXtH+/fu1ePHiAddWrlypnp4elZSUqLOzU7m5uWpoaFBaWlpCigUAAO7nMcaY4S7iWNFoVD6fT5FIROnp6cNdDs4hk1ZtHu4S4vb+mjmnXwQAFsTz/s13uwAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsijt8fPjhh/rOd76jSy65RKmpqfrqV7+qHTt2ONeNMaqoqFBmZqZSUlJUUFCg1tbWhBYNAADcK67w0dnZqeuvv16jRo3SSy+9pLfeeku/+tWvdNFFFzlrqqqqVF1drdraWrW0tCgQCKiwsFBdXV2Jrh0AALjQyHgWP/bYY8rKytL69euduUmTJjn/bYxRTU2NysvLVVxcLEmqq6uT3+9XfX29lixZkpiqAQCAa8V18vHCCy9oxowZuuOOOzRu3Dhdc801evrpp53rbW1tCofDKioqcua8Xq/y8/PV3NycuKoBAIBrxRU+3nvvPa1du1bBYFAvv/yyli5dqh/+8Id65plnJEnhcFiS5Pf7Y57n9/uda8fr7e1VNBqNGQAAIHnF9bHLkSNHNGPGDIVCIUnSNddco9bWVq1du1bf/e53nXUejyfmecaYAXP9KisrtXr16njrBgAALhXXyUdGRoYmT54cM3fVVVdp//79kqRAICBJA045Ojo6BpyG9CsrK1MkEnFGe3t7PCUBAACXiSt8XH/99dq7d2/M3DvvvKOJEydKkrKzsxUIBNTY2Ohc7+vrU1NTk/Ly8k74ml6vV+np6TEDAAAkr7g+dnnggQeUl5enUCikb3/72/rHP/6hdevWad26dZKOftxSWlqqUCikYDCoYDCoUCik1NRUzZ8/f0gaAAAA7hJX+Lj22mu1adMmlZWV6ec//7mys7NVU1OjBQsWOGtWrlypnp4elZSUqLOzU7m5uWpoaFBaWlrCiwcAAO7jMcaY4S7iWNFoVD6fT5FIhI9gYNWkVZuHu4S4vb9mznCXAACS4nv/5rtdAACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFVxhY+Kigp5PJ6YEQgEnOvGGFVUVCgzM1MpKSkqKChQa2trwosGAADuFffJx5QpU3TgwAFn7Nmzx7lWVVWl6upq1dbWqqWlRYFAQIWFherq6kpo0QAAwL3iDh8jR45UIBBwxtixYyUdPfWoqalReXm5iouLlZOTo7q6OnV3d6u+vj7hhQMAAHeKO3y8++67yszMVHZ2tu666y699957kqS2tjaFw2EVFRU5a71er/Lz89Xc3HzS1+vt7VU0Go0ZAAAgecUVPnJzc/XMM8/o5Zdf1tNPP61wOKy8vDx98sknCofDkiS/3x/zHL/f71w7kcrKSvl8PmdkZWUNog0AAOAWcYWP2bNn65vf/Kauvvpq3XLLLdq8ebMkqa6uzlnj8XhinmOMGTB3rLKyMkUiEWe0t7fHUxIAAHCZM/pV2wsuuEBXX3213n33Xee3Xo4/5ejo6BhwGnIsr9er9PT0mAEAAJLXGYWP3t5evf3228rIyFB2drYCgYAaGxud6319fWpqalJeXt4ZFwoAAJLDyHgW//jHP9bcuXM1YcIEdXR06Be/+IWi0agWLlwoj8ej0tJShUIhBYNBBYNBhUIhpaamav78+UNVPwAAcJm4wscHH3ygu+++Wx9//LHGjh2r6667Ttu2bdPEiRMlSStXrlRPT49KSkrU2dmp3NxcNTQ0KC0tbUiKBwAA7uMxxpjhLuJY0WhUPp9PkUiE+z9g1aRVm4e7hLi9v2bOcJcAAJLie//mu10AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVp1R+KisrJTH41FpaakzZ4xRRUWFMjMzlZKSooKCArW2tp5pnQAAIEkMOny0tLRo3bp1mjp1asx8VVWVqqurVVtbq5aWFgUCARUWFqqrq+uMiwUAAO43qPDx2WefacGCBXr66ad18cUXO/PGGNXU1Ki8vFzFxcXKyclRXV2duru7VV9fn7CiAQCAew0qfCxbtkxz5szRLbfcEjPf1tamcDisoqIiZ87r9So/P1/Nzc0nfK3e3l5Fo9GYAQAAktfIeJ+wYcMG7dy5Uy0tLQOuhcNhSZLf74+Z9/v92rdv3wlfr7KyUqtXr463DAAA4FJxnXy0t7fr/vvv17PPPqvzzz//pOs8Hk/MY2PMgLl+ZWVlikQizmhvb4+nJAAA4DJxnXzs2LFDHR0dmj59ujN3+PBhbd26VbW1tdq7d6+koycgGRkZzpqOjo4BpyH9vF6vvF7vYGoHAAAuFNfJx80336w9e/Zo9+7dzpgxY4YWLFig3bt367LLLlMgEFBjY6PznL6+PjU1NSkvLy/hxQMAAPeJ6+QjLS1NOTk5MXMXXHCBLrnkEme+tLRUoVBIwWBQwWBQoVBIqampmj9/fuKqBgAArhX3Daens3LlSvX09KikpESdnZ3Kzc1VQ0OD0tLSEv2jAACAC3mMMWa4izhWNBqVz+dTJBJRenr6cJeDc8ikVZuHu4S4vb9mznCXAACS4nv/5rtdAACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFVxhY+1a9dq6tSpSk9PV3p6umbOnKmXXnrJuW6MUUVFhTIzM5WSkqKCggK1trYmvGgAAOBecYWP8ePHa82aNdq+fbu2b9+uWbNmad68eU7AqKqqUnV1tWpra9XS0qJAIKDCwkJ1dXUNSfEAAMB94gofc+fO1a233qorrrhCV1xxhR599FFdeOGF2rZtm4wxqqmpUXl5uYqLi5WTk6O6ujp1d3ervr5+qOoHAAAuM+h7Pg4fPqwNGzbo4MGDmjlzptra2hQOh1VUVOSs8Xq9ys/PV3Nz80lfp7e3V9FoNGYAAIDkFXf42LNnjy688EJ5vV4tXbpUmzZt0uTJkxUOhyVJfr8/Zr3f73eunUhlZaV8Pp8zsrKy4i0JAAC4SNzh48orr9Tu3bu1bds23XvvvVq4cKHeeust57rH44lZb4wZMHessrIyRSIRZ7S3t8dbEgAAcJGR8T5h9OjRuvzyyyVJM2bMUEtLi5544gk9+OCDkqRwOKyMjAxnfUdHx4DTkGN5vV55vd54ywAAAC51xn/nwxij3t5eZWdnKxAIqLGx0bnW19enpqYm5eXlnemPAQAASSKuk4+HHnpIs2fPVlZWlrq6urRhwwa9/vrr2rJlizwej0pLSxUKhRQMBhUMBhUKhZSamqr58+cPVf0AAMBl4gof//nPf3TPPffowIED8vl8mjp1qrZs2aLCwkJJ0sqVK9XT06OSkhJ1dnYqNzdXDQ0NSktLG5LiAQCA+3iMMWa4izhWNBqVz+dTJBJRenr6cJeDc8ikVZuHu4S4vb9mznCXAACS4nv/5rtdAACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFg1crgLQHKatGrzcJcAADhLcfIBAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwKq7wUVlZqWuvvVZpaWkaN26cbr/9du3duzdmjTFGFRUVyszMVEpKigoKCtTa2prQogEAgHvFFT6ampq0bNkybdu2TY2NjTp06JCKiop08OBBZ01VVZWqq6tVW1urlpYWBQIBFRYWqqurK+HFAwAA9xkZz+ItW7bEPF6/fr3GjRunHTt26KabbpIxRjU1NSovL1dxcbEkqa6uTn6/X/X19VqyZEniKgcAAK50Rvd8RCIRSdKYMWMkSW1tbQqHwyoqKnLWeL1e5efnq7m5+YSv0dvbq2g0GjMAAEDyGnT4MMZoxYoVuuGGG5STkyNJCofDkiS/3x+z1u/3O9eOV1lZKZ/P54ysrKzBlgQAAFxg0OFj+fLlevPNN/WnP/1pwDWPxxPz2BgzYK5fWVmZIpGIM9rb2wdbEgAAcIG47vnod9999+mFF17Q1q1bNX78eGc+EAhIOnoCkpGR4cx3dHQMOA3p5/V65fV6B1MGAABwobhOPowxWr58uTZu3KhXX31V2dnZMdezs7MVCATU2NjozPX19ampqUl5eXmJqRgAALhaXCcfy5YtU319vf7yl78oLS3NuY/D5/MpJSVFHo9HpaWlCoVCCgaDCgaDCoVCSk1N1fz584ekAQAA4C5xhY+1a9dKkgoKCmLm169fr0WLFkmSVq5cqZ6eHpWUlKizs1O5ublqaGhQWlpaQgoGAADuFlf4MMacdo3H41FFRYUqKioGWxMAAEhifLcLAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwa1J9XB3B2mLRq83CXELf318wZ7hIADDNOPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYFXc4WPr1q2aO3euMjMz5fF49Pzzz8dcN8aooqJCmZmZSklJUUFBgVpbWxNVLwAAcLm4w8fBgwc1bdo01dbWnvB6VVWVqqurVVtbq5aWFgUCARUWFqqrq+uMiwUAAO43Mt4nzJ49W7Nnzz7hNWOMampqVF5eruLiYklSXV2d/H6/6uvrtWTJkjOrFgAAuF5C7/loa2tTOBxWUVGRM+f1epWfn6/m5uYTPqe3t1fRaDRmAACA5JXQ8BEOhyVJfr8/Zt7v9zvXjldZWSmfz+eMrKysRJYEAADOMkPy2y4ejyfmsTFmwFy/srIyRSIRZ7S3tw9FSQAA4CwR9z0fpxIIBCQdPQHJyMhw5js6OgachvTzer3yer2JLAMAAJzFEnrykZ2drUAgoMbGRmeur69PTU1NysvLS+SPAgAALhX3ycdnn32mf//7387jtrY27d69W2PGjNGECRNUWlqqUCikYDCoYDCoUCik1NRUzZ8/P6GFAwBObdKqzcNdQtzeXzNnuEuABXGHj+3bt+trX/ua83jFihWSpIULF+oPf/iDVq5cqZ6eHpWUlKizs1O5ublqaGhQWlpa4qoGAACuFXf4KCgokDHmpNc9Ho8qKipUUVFxJnUBAIAkxXe7AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwKq4/7w6AJwJN37ZmcQXngGJxMkHAACwivABAACsInwAAACrCB8AAMAqbjgFAJw13HhDMjcjx4+TDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABW8Xc+XMCNv/cOJBv+HQKJw8kHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwKoh+yNjv/3tb/X444/rwIEDmjJlimpqanTjjTcO1Y/7wvhDQQCARHLj+8r7a+YM688fkpOP5557TqWlpSovL9euXbt04403avbs2dq/f/9Q/DgAAOAiQxI+qqur9b3vfU/f//73ddVVV6mmpkZZWVlau3btUPw4AADgIgn/2KWvr087duzQqlWrYuaLiorU3Nw8YH1vb696e3udx5FIRJIUjUYTXZok6Uhv95C8LgAAbjEU77H9r2mMOe3ahIePjz/+WIcPH5bf74+Z9/v9CofDA9ZXVlZq9erVA+azsrISXRoAAJDkqxm61+7q6pLP5zvlmiG74dTj8cQ8NsYMmJOksrIyrVixwnl85MgR/fe//9Ull1xywvXDLRqNKisrS+3t7UpPTx/ucobMudAnPSaPc6FPekweydqnMUZdXV3KzMw87dqEh49LL71UI0aMGHDK0dHRMeA0RJK8Xq+8Xm/M3EUXXZToshIuPT09qf5HczLnQp/0mDzOhT7pMXkkY5+nO/Hol/AbTkePHq3p06ersbExZr6xsVF5eXmJ/nEAAMBlhuRjlxUrVuiee+7RjBkzNHPmTK1bt0779+/X0qVLh+LHAQAAFxmS8HHnnXfqk08+0c9//nMdOHBAOTk5evHFFzVx4sSh+HFWeb1ePfLIIwM+Kko250Kf9Jg8zoU+6TF5nCt9norHfJHfiQEAAEgQvtsFAABYRfgAAABWET4AAIBVhA8AAGAV4UPS1q1bNXfuXGVmZsrj8ej555+PuW6MUUVFhTIzM5WSkqKCggK1trbGrOnt7dV9992nSy+9VBdccIG+8Y1v6IMPPrDYxemdrs9FixbJ4/HEjOuuuy5mzdneZ2Vlpa699lqlpaVp3Lhxuv3227V3796YNW7fzy/So9v3cu3atZo6darzR5hmzpypl156ybnu9j3sd7o+3b6PJ1JZWSmPx6PS0lJnLln2s9+JekzGvTwThA9JBw8e1LRp01RbW3vC61VVVaqurlZtba1aWloUCARUWFiorq4uZ01paak2bdqkDRs26I033tBnn32m2267TYcPH7bVxmmdrk9J+vrXv64DBw4448UXX4y5frb32dTUpGXLlmnbtm1qbGzUoUOHVFRUpIMHDzpr3L6fX6RHyd17OX78eK1Zs0bbt2/X9u3bNWvWLM2bN895Q3L7HvY7XZ+Su/fxeC0tLVq3bp2mTp0aM58s+ymdvEcpufbyjBnEkGQ2bdrkPD5y5IgJBAJmzZo1ztznn39ufD6feeqpp4wxxnz66adm1KhRZsOGDc6aDz/80Jx33nlmy5Yt1mqPx/F9GmPMwoULzbx58076HDf22dHRYSSZpqYmY0xy7ufxPRqTnHt58cUXm9/97ndJuYfH6u/TmOTax66uLhMMBk1jY6PJz883999/vzEmuf5NnqxHY5JrLxOBk4/TaGtrUzgcVlFRkTPn9XqVn5+v5uZmSdKOHTv0v//9L2ZNZmamcnJynDVu8frrr2vcuHG64oor9IMf/EAdHR3ONTf2GYlEJEljxoyRlJz7eXyP/ZJlLw8fPqwNGzbo4MGDmjlzZlLuoTSwz37Jso/Lli3TnDlzdMstt8TMJ9N+nqzHfsmyl4kwZN9qmyz6vyDv+C/F8/v92rdvn7Nm9OjRuvjiiwesOf4L9s5ms2fP1h133KGJEyeqra1NDz/8sGbNmqUdO3bI6/W6rk9jjFasWKEbbrhBOTk5kpJvP0/Uo5Qce7lnzx7NnDlTn3/+uS688EJt2rRJkydPdv6POFn28GR9Ssmxj5K0YcMG7dy5Uy0tLQOuJcu/yVP1KCXPXiYK4eML8ng8MY+NMQPmjvdF1pxN7rzzTue/c3JyNGPGDE2cOFGbN29WcXHxSZ93tva5fPlyvfnmm3rjjTcGXEuW/TxZj8mwl1deeaV2796tTz/9VH/+85+1cOFCNTU1OdeTZQ9P1ufkyZOTYh/b29t1//33q6GhQeeff/5J17l5P79Ij8mwl4nExy6nEQgEJGlA8uzo6HCSeiAQUF9fnzo7O0+6xo0yMjI0ceJEvfvuu5Lc1ed9992nF154Qa+99prGjx/vzCfTfp6sxxNx416OHj1al19+uWbMmKHKykpNmzZNTzzxRFLtoXTyPk/Ejfu4Y8cOdXR0aPr06Ro5cqRGjhyppqYm/frXv9bIkSOdOt28n6fr8UQ3jLpxLxOJ8HEa2dnZCgQCamxsdOb6+vrU1NSkvLw8SdL06dM1atSomDUHDhzQv/71L2eNG33yySdqb29XRkaGJHf0aYzR8uXLtXHjRr366qvKzs6OuZ4M+3m6Hk/EjXt5PGOMent7k2IPT6W/zxNx4z7efPPN2rNnj3bv3u2MGTNmaMGCBdq9e7cuu+wy1+/n6XocMWLEgOe4cS8TyvYdrmejrq4us2vXLrNr1y4jyVRXV5tdu3aZffv2GWOMWbNmjfH5fGbjxo1mz5495u677zYZGRkmGo06r7F06VIzfvx488orr5idO3eaWbNmmWnTpplDhw4NV1sDnKrPrq4u86Mf/cg0NzebtrY289prr5mZM2eaL33pS67q89577zU+n8+8/vrr5sCBA87o7u521rh9P0/XYzLsZVlZmdm6datpa2szb775pnnooYfMeeedZxoaGowx7t/DfqfqMxn28WSO/02QZNnPYx3bYzLv5WARPowxr732mpE0YCxcuNAYc/RXwR555BETCASM1+s1N910k9mzZ0/Ma/T09Jjly5ebMWPGmJSUFHPbbbeZ/fv3D0M3J3eqPru7u01RUZEZO3asGTVqlJkwYYJZuHDhgB7O9j5P1J8ks379emeN2/fzdD0mw14uXrzYTJw40YwePdqMHTvW3HzzzU7wMMb9e9jvVH0mwz6ezPHhI1n281jH9pjMezlYHmOMsXfOAgAAznXc8wEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALDq/wBhsLD6tAub6QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array([287, 238, 245, 226, 190, 276, 208, 226, 226, 226, 208, 226, 243, 226, 226, 182, 241, 226,\n",
    "                 276, 226, 226, 226, 208, 226, 226, 226, 276, 226, 226, 226, 182, 218, 219, 208, 226, 226,\n",
    "                 268, 226, 203, 226, 208, 208, 282, 208, 208, 172, 208, 226, 186, 218, 226, 208, 226, 226,\n",
    "                 241, 232, 518, 303, 226, 208, 226, 226, 287, 188, 235, 222, 193, 190, 268, 208, 226, 226,\n",
    "                 276, 461, 268, 226, 218, 266, 218, 226, 256, 218, 195, 201, 226, 226, 222, 203, 208, 226,\n",
    "                 226, 208, 226, 272, 226, 208, 221, 195, 226, 241, 226, 382, 226, 459, 146, 182, 226, 232,\n",
    "                 287, 226, 226, 208, 226, 218, 352, 226, 226, 266, 226, 226, 198, 326, 208, 226, 222, 190,\n",
    "                 232, 226, 208, 226, 226, 226, 232, 226, 200, 226, 226, 226, 226, 459, 226, 226, 208, 266,\n",
    "                 222, 226, 333, 209, 226, 208])\n",
    "data_2 = np.array([208, 226, 222, 226, 226, 295, 226, 276, 276, 226, 216, 208, 226, 226, 172, 170, 226, 208,\n",
    "                   364, 226, 266, 226, 208, 378, 226, 190, 203, 226, 226, 208, 226, 198, 276, 226, 226, 276,\n",
    "                   190, 208, 226, 208, 222, 182, 383, 182, 230, 226, 226, 222, 226, 208, 253, 370, 258, 139,\n",
    "                   274, 226, 411, 287, 423, 313, 276, 226, 248, 218, 180, 424, 226, 276, 158, 319, 180, 217,\n",
    "                   218, 226, 226, 398, 226, 166, 226, 226, 226, 203, 226, 85, 208, 188, 213, 356, 221, 180,\n",
    "                   195, 195, 208, 180, 208, 217, 276, 222, 334, 208, 226, 390, 305, 226, 208, 226, 424, 221,\n",
    "                   251, 190, 208, 182, 226, 364, 172, 420, 195, 226, 276, 226, 226, 478, 226, 200, 168, 259,\n",
    "                   226, 364, 226, 230, 263, 388, 226, 226, 172, 237, 226, 226, 166, 218, 155, 292, 226, 226,\n",
    "                   226, 266, 226, 241, 200, 331])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
